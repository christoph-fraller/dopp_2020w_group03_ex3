{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dopp_2020w_group03_ex3_with_git.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_n-eLlFeXXOH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoph-fraller/dopp_2020w_group03_ex3/blob/main/dopp_2020w_group03_ex3_with_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n-eLlFeXXOH"
      },
      "source": [
        "# Generate SSH-Keys for Accessing Git Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMNYj7F2o5Fz"
      },
      "source": [
        "# import and mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_vOiBlVR6Of"
      },
      "source": [
        "# generate ssh keys (insert your username@github.com + hit enter when prompted for any answer)\r\n",
        "! ssh-keygen -t rsa -b 4096 -C 'yummakan@github.com'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2185rH9fXBe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYpBS4KYhhf"
      },
      "source": [
        "# check whether or not the ssh keys have been created ('id_rsa' and 'id_rsa.pub' should be displayed)\r\n",
        "! ls /root/.ssh/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rx2E_IgUraa"
      },
      "source": [
        "# create directory for saving the ssh keys\r\n",
        "! mkdir -p /content/drive/MyDrive/Ssh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucFTIsSEVeZ0"
      },
      "source": [
        "# copy ssh keys from /root/.ssh/* to /content/drive/MyDrive/Ssh/*\r\n",
        "! cp /root/.ssh/id_rsa /content/drive/MyDrive/Ssh/\r\n",
        "! cp /root/.ssh/id_rsa.pub /content/drive/MyDrive/Ssh/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekNM8je8SefW"
      },
      "source": [
        "# display public ssh key for copy/paste\r\n",
        "! cat /content/drive/MyDrive/Ssh/id_rsa.pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqNlD7pxTI6I"
      },
      "source": [
        "# add github to known hosts and adapt file access permissions\r\n",
        "! ssh-keyscan github.com >> /root/.ssh/known_hosts\r\n",
        "! chmod 644 /root/.ssh/known_hosts\r\n",
        "! chmod 600 /root/.ssh/id_rsa\r\n",
        "! ssh -T git@github.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sqVqK8YHeSS"
      },
      "source": [
        "# Git Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57DJRGnO5B0"
      },
      "source": [
        "# git config settings (replace with your credentials)\r\n",
        "! git config --global user.email \"maximilian.loesch97@gmail.com\"\r\n",
        "! git config --global user.name \"Maxiking1997\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEkuNsHeC8bF"
      },
      "source": [
        "# create directory for git repositories\r\n",
        "! mkdir -p /content/drive/MyDrive/Git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgI7KaUuVyPG"
      },
      "source": [
        "# git-clone has to be performed only once when setting up the git repo at your google drive\r\n",
        "! git clone git@github.com:christoph-fraller/dopp_2020w_group03_ex3.git /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb6rrvXMI4i_"
      },
      "source": [
        "## Important Shell and Git Commands\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDb8FOn5JC2h"
      },
      "source": [
        "**NOTICE:** Always ensure that you are in the right directory when performing git commands (e.g. /content/drive/MyDrive/Git/dopp_2020w_group03_ex3). In case of any issues that might occur when switching directories it is highly recommended to restart the runtime engine (CTRL + M + .)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibAYNQjLDed"
      },
      "source": [
        "# check current working directory\r\n",
        "! pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6F2toRiJ1yE"
      },
      "source": [
        "# switch to specified working directory\r\n",
        "%cd /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKxY_7fJuRC"
      },
      "source": [
        "# list content of current working directory\r\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuJokwbqLMdf"
      },
      "source": [
        "# check git status\r\n",
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViV1YHxQLQZH"
      },
      "source": [
        "# always perform a git pull before you start working or commit/push some changes\r\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXfdcdIXOTk7"
      },
      "source": [
        "# add a new data file to git repo directly from colab\r\n",
        "# at first upload the file into the folder of your google drive\r\n",
        "#! git add data/data_indicators_2.csv\r\n",
        "#! git commit -m 'New file added.'\r\n",
        "#! git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SZJVIvmWrVe"
      },
      "source": [
        "# Perform these steps everytime when a new session has been started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOh292DlLnbG"
      },
      "source": [
        "# import and mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox9qElcvxY8p"
      },
      "source": [
        "# create directory\r\n",
        "! mkdir -p /root/.ssh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKkBeH7Ww_B"
      },
      "source": [
        "# copy ssh keys from /content/drive/MyDrive/Ssh/* to /root/.ssh/*\r\n",
        "! cp /content/drive/MyDrive/Ssh/id_rsa /root/.ssh/\r\n",
        "! cp /content/drive/MyDrive/Ssh/id_rsa.pub /root/.ssh/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD1i__xSX8s4"
      },
      "source": [
        "# add github to known hosts and adapt file access permissions\r\n",
        "! ssh-keyscan github.com >> /root/.ssh/known_hosts\r\n",
        "! chmod 644 /root/.ssh/known_hosts\r\n",
        "! chmod 600 /root/.ssh/id_rsa\r\n",
        "! ssh -T git@github.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMtv6CAyFAx"
      },
      "source": [
        "# switch to specified working directory\r\n",
        "%cd /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e75ezFO2XS4_"
      },
      "source": [
        "# always perform a git pull before you start working or commit/push some changes\r\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4898HwMCGar"
      },
      "source": [
        "## Geopanda installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkUXPXQlCQX1"
      },
      "source": [
        "# Important library for many geopython libraries\r\n",
        "!apt install gdal-bin python-gdal python3-gdal \r\n",
        "# Install rtree - Geopandas requirment\r\n",
        "!apt install python3-rtree \r\n",
        "# Install Geopandas\r\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\r\n",
        "# Install descartes - Geopandas requirment\r\n",
        "!pip install descartes \r\n",
        "# Install Folium for Geographic data visualization\r\n",
        "!pip install folium\r\n",
        "# Install plotlyExpress\r\n",
        "!pip install plotly_express"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4PMn1CYaWbu"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sb\r\n",
        "import geopandas\r\n",
        "from ipywidgets import IntSlider, interact\r\n",
        "from scipy import stats\r\n",
        "from statistics import mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAa8Euy1xZYT"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9p9vTpUxlrp"
      },
      "source": [
        "## Load and merge income data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-clO4Ga8bOK"
      },
      "source": [
        "def load_merge_income_data():\r\n",
        "  \r\n",
        "  # load income data from csv\r\n",
        "  income_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/undata_gni_per_capita.csv', sep = ';')\r\n",
        "\r\n",
        "  # extend income data by adding an entry for each combination of (calendar_year, country_code) due to there are currently no missing entries in the data\r\n",
        "  country_data_list = income_data[['country_code', 'country_name']].drop_duplicates().values.tolist()\r\n",
        "  output_list = []\r\n",
        "  for lst in country_data_list:\r\n",
        "      country_code = lst[0]\r\n",
        "      country_name = lst[1]\r\n",
        "      for calendar_year in range(1970, 2019):\r\n",
        "        output_list.append([calendar_year, country_code, country_name])\r\n",
        "  df = pd.DataFrame(output_list, columns = ['calendar_year', 'country_code', 'country_name'])\r\n",
        "  income_data_complete = df.merge(income_data[['calendar_year', 'country_code', 'gni_per_capita_us_dollar']], how = 'left', on = ['calendar_year', 'country_code'])\r\n",
        "\r\n",
        "  # load population data from csv\r\n",
        "  population_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/undata_population_total.csv', sep = ';', \r\n",
        "                                usecols = ['country_code', 'calendar_year', 'population_total'])\r\n",
        "  population_data.drop_duplicates(inplace = True)\r\n",
        "  population_data['population_total'] = population_data['population_total'] * 1000 # total population is specified in 1000\r\n",
        "\r\n",
        "  # load country codes from csv\r\n",
        "  country_codes = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/iso3166_unsd_country_codes.csv', sep = ';', \r\n",
        "                              usecols = ['m49_code', 'iso_alpha2_code', 'iso_alpha3_code', 'small_island_developing_states'])\r\n",
        "\r\n",
        "  # merge income with population data and country codes\r\n",
        "  output_data = income_data_complete.merge(population_data, how = 'left', on = ['calendar_year', 'country_code'])\r\n",
        "  output_data = output_data.merge(country_codes, how = 'left', left_on = 'country_code', right_on = 'm49_code')\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "merged_income_data = load_merge_income_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcwPvGpE-xpZ"
      },
      "source": [
        "## Clean issues in income data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRAd80L-3vC0"
      },
      "source": [
        "def clean_income_data(input_data):\r\n",
        "  \r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop duplicate information at column-level\r\n",
        "  output_data.drop(['country_code'], axis = 1, inplace = True)\r\n",
        "  output_data.rename(columns = {'country_code': 'm49_code'}, inplace = True) \r\n",
        "\r\n",
        "  # replace values of column 'small_island_developing_states' by True/False\r\n",
        "  output_data['small_island_developing_states'].replace('x', True, inplace = True)\r\n",
        "  output_data['small_island_developing_states'].fillna(False, inplace = True)\r\n",
        "\r\n",
        "  # fix issues at column 'small_island_developing_states' for some countries\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'Former Netherlands Antilles'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'United Republic of Tanzania: Mainland'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'United Republic of Tanzania: Zanzibar'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "\r\n",
        "  # drop small island countries and reset row index\r\n",
        "  output_data.drop(output_data[output_data['small_island_developing_states'] == True].index, inplace = True)\r\n",
        "  output_data.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  # reorder colums of dataframe\r\n",
        "  output_data = output_data[['calendar_year', 'iso_alpha3_code', 'iso_alpha2_code', 'm49_code', 'country_name', 'population_total', 'gni_per_capita_us_dollar']]\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "cleaned_income_data = clean_income_data(merged_income_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrR6-ZxGAfJh"
      },
      "source": [
        "## Exploring missing values in income data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jKXCYG-Al7g"
      },
      "source": [
        "# get an overview of missing values in income data\r\n",
        "# it seems there is pattern between the missing values of the columns iso_alpha3_code, iso_alpha2_code, m49_code and population_total\r\n",
        "ax = plt.axes()\r\n",
        "sb.heatmap(cleaned_income_data.isna(), cbar = False);\r\n",
        "ax.set_title('Visualization of missing values in income dataset')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3AL9oR7BUjL"
      },
      "source": [
        "# ad 1) missing values in country codes\r\n",
        "# obtain countries with missing country codes (iso_alpha3_code, iso_alpha2_code, m49_code)\r\n",
        "iso_alpha3_code_set = set(cleaned_income_data.loc[cleaned_income_data['iso_alpha3_code'].isna()].country_name.unique().tolist())\r\n",
        "iso_alpha2_code_set = set(cleaned_income_data.loc[cleaned_income_data['iso_alpha2_code'].isna()].country_name.unique().tolist())\r\n",
        "m49_code_set = set(cleaned_income_data.loc[cleaned_income_data['m49_code'].isna()].country_name.unique().tolist())\r\n",
        "union_list_sorted = sorted(iso_alpha3_code_set | iso_alpha2_code_set | m49_code_set)\r\n",
        "print('\\nCountries with missing entries in their country codes:')\r\n",
        "print('------------------------------------------------------')\r\n",
        "print(*union_list_sorted, sep = '\\n')\r\n",
        "\r\n",
        "# strategy on dealing with missing in country codes:\r\n",
        "\r\n",
        "## most of the missing entries in country codes can be traced back to former countries that no longer exist and therefore their codes are missing in \r\n",
        "## the actual iso3166 standard but in order to obtain a complete dataset we will refill based on historical data: Former Czechoslovakia, Former Ethiopia,\r\n",
        "## Former Sudan, Former USSR, Former Yugoslavia, Yemen: Former Democratic Yemen, Yemen: Former Yemen Arab Republic\r\n",
        "\r\n",
        "## Nambia's iso_alpha2_code corresponds to 'NA', which is interpreted as NA per default, we have to fix this when inserting the other missing country codes\r\n",
        "\r\n",
        "## Kosovo has declared its independence from Serbia in 2008 but until today this declaration is quite controversial\r\n",
        "## due to reasons of simplicity and without being politically, we have decided to exclude the Kosovo from our analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaxkFISlKU6I"
      },
      "source": [
        "# ad 2) missing values in population\r\n",
        "# obtain countries with population total \r\n",
        "population_list_sorted = sorted(cleaned_income_data.loc[cleaned_income_data['population_total'].isna()].country_name.unique().tolist())\r\n",
        "print('\\nCountries with missing entries in their population values:')\r\n",
        "print('----------------------------------------------------------')\r\n",
        "print(*population_list_sorted, sep = '\\n')\r\n",
        "\r\n",
        "# strategy on dealing with missing in population values:\r\n",
        "\r\n",
        "## missing entries in population values can be traced back to former countries that no longer exist\r\n",
        "## because we know the former composition of that countries we can easily calculate their population values based on their components\r\n",
        "## at least this is a possible approach for large countries that have been splitted up: \r\n",
        "### Former Sudan, Former USSR, Former Yugoslavia, Yemen: Former Democratic Yemen, Yemen: Former Yemen Arab Republic\r\n",
        "### Former Czechoslovakia -> Czech Republic, Slovakia,\r\n",
        "### Former Ethiopia -> Ethiopia, Eritrea,\r\n",
        "### Former Sudan -> Sudan, South Sudan],\r\n",
        "### Former USSR -> Armenia, Azerbaijan, Belarus, Estonia, Georgia, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Republic of Moldova, Russian Federation, Tajikistan, Turkmenistan, Ukraine, Uzbekistan\r\n",
        "### Former Yugoslavia -> Bosnia and Herzegovina, Croatia, Montenegro, Republic of North Macedonia, Serbia, Slovenia\r\n",
        "\r\n",
        "## in case of Yemen we have a merge of two former countries for which the above mentioned approach is not possible\r\n",
        "## even if such a merge of two quite similiar countries (at least in gni_per_capita) is politically important, for our purposes it is not\r\n",
        "## therefore we decided to consider Yemen in our data as one country for the entire observation period\r\n",
        "\r\n",
        "## Kosovo has declared its independence from Serbia in 2008 but until today this declaration is quite controversial\r\n",
        "## due to reasons of simplicity and without being politically, we have decided to exclude the Kosovo from our analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD71IbE_PGoq"
      },
      "source": [
        "# ad 3) missing values in gni per capita\r\n",
        "# obtain countries with gni per capita\r\n",
        "gni_null_values = cleaned_income_data.gni_per_capita_us_dollar.isnull().groupby(cleaned_income_data['country_name']).sum().astype(int).reset_index(name = 'null_count')\r\n",
        "print('\\nCountries with missing entries in their gni per capita values:')\r\n",
        "print('--------------------------------------------------------------')\r\n",
        "print(gni_null_values[gni_null_values['null_count'] > 0])\r\n",
        "\r\n",
        "# strategy on dealing with missing in gni per capita values:\r\n",
        "## when taking a closer look at the data, almost all of the missing values at gni per capita can be traced back to years for which a country does not exist\r\n",
        "## therefore such entries with missing values at gni per capita can be safely removed but for Yemen a special handling will be required: \r\n",
        "## due to the similarity of the Yemen: Former Democratic Yemen and Yemen: Former Yemen Arab Republic we decided to calculate the mean of the gni per capita\r\n",
        "## of both countries and use it to replace the historical missing values of Yemen, for our work the separation between that two former countries is neglible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2DP9IQR0FX2"
      },
      "source": [
        "## Handling missing country codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9PNnKnP0EaC"
      },
      "source": [
        "def handle_missing_country_codes(input_data):\r\n",
        "\r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop entries of Kosovo\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Kosovo'].index, inplace = True)\r\n",
        "  output_data.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  # load formerly used country codes from csv, set na_filter to false in order to fix the issue of Namibia's iso_alpha2_code\r\n",
        "  former_country_codes = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/iso3166_formerly_used_country_codes.csv', sep = ';', na_filter = False)\r\n",
        "\r\n",
        "  country_codes_list = ['iso_alpha3_code', 'iso_alpha2_code', 'm49_code']   \r\n",
        "\r\n",
        "  # insert missing values from former_country_codes\r\n",
        "  for row_index in range(0, len(output_data)):\r\n",
        "      \r\n",
        "    for country_code in country_codes_list:\r\n",
        "        \r\n",
        "      # check if country code value is missing\r\n",
        "      if pd.isnull(output_data.loc[row_index, country_code]):\r\n",
        "\r\n",
        "        # insert missing country code\r\n",
        "        output_data.loc[row_index, country_code] = former_country_codes.loc[former_country_codes[former_country_codes['country_name'] == output_data.loc[row_index, 'country_name']].index[0], country_code]\r\n",
        "  \r\n",
        "  return output_data\r\n",
        "    \r\n",
        "income_data_country_codes_complete = handle_missing_country_codes(cleaned_income_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs8IqtlbG9_1"
      },
      "source": [
        "## Compute missing population data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ELhXWUHCYm"
      },
      "source": [
        "def compute_missing_population_total(input_data):\r\n",
        "\r\n",
        "    output_data = input_data.copy()\r\n",
        "\r\n",
        "    former_country_lists = [['Former Czechoslovakia', 'Czech Republic', 'Slovakia'],\r\n",
        "                             ['Former Ethiopia', 'Ethiopia', 'Eritrea'],\r\n",
        "                             ['Former Sudan', 'Sudan', 'South Sudan'],\r\n",
        "                             ['Former USSR', 'Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', \r\n",
        "                              'Republic of Moldova', 'Russian Federation', 'Tajikistan', 'Turkmenistan', 'Ukraine', 'Uzbekistan'],\r\n",
        "                             ['Former Yugoslavia', 'Bosnia and Herzegovina', 'Croatia', 'Montenegro', 'Republic of North Macedonia', 'Serbia', 'Slovenia']]\r\n",
        "\r\n",
        "    for country_list in former_country_lists:\r\n",
        "\r\n",
        "      # get first list elem of list\r\n",
        "      former_country_name = country_list.pop(0)\r\n",
        "\r\n",
        "      # get list of calendar_years\r\n",
        "      calendar_year_list = output_data.loc[output_data['country_name'] == former_country_name].calendar_year.tolist()\r\n",
        "\r\n",
        "      for calendar_year in calendar_year_list:\r\n",
        "        \r\n",
        "        # get current index of former_country at particular calender_year\r\n",
        "        curr_former_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == former_country_name)].population_total.index.max()\r\n",
        "        \r\n",
        "        # initialize new_population_total\r\n",
        "        new_population_total = 0\r\n",
        "\r\n",
        "        for country_name in country_list:\r\n",
        "          \r\n",
        "          if pd.isnull(output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == country_name)].gni_per_capita_us_dollar).bool():\r\n",
        "            \r\n",
        "            # get current index of country at particular calender_year  \r\n",
        "            curr_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == country_name)].population_total.index.max()\r\n",
        "\r\n",
        "            # increment new_population_total by population_total of curr_country_index at particular calender_year \r\n",
        "            new_population_total += output_data.loc[curr_country_index, 'population_total']\r\n",
        "\r\n",
        "        # update population_total of former_country with new_population_total at particular calender_year \r\n",
        "        output_data.loc[curr_former_country_index, 'population_total'] = new_population_total if new_population_total > 0 else np.nan\r\n",
        "\r\n",
        "    return output_data\r\n",
        "    \r\n",
        "income_data_population_total_complete = compute_missing_population_total(income_data_country_codes_complete)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWLF76kOJ0vU"
      },
      "source": [
        "## Fix missing gni per capita values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnEMO_CUKHi_"
      },
      "source": [
        "def fix_missing_gni_per_capita_values(input_data):\r\n",
        "  \r\n",
        "  output_data = input_data.copy()\r\n",
        "  \r\n",
        "  # set index on calendar_year\r\n",
        "  output_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  # special handling for 'Yemen': \r\n",
        "  # compute mean of gni per capita from 'Yemen: Former Democratic Yemen' and 'Yemen: Former Yemen Arab Republic'\r\n",
        "  # and replace missing values of 'Yemen' with the computed mean\r\n",
        "  yemen_missing_gni_values = (output_data[output_data['country_name'] == 'Yemen: Former Democratic Yemen'].gni_per_capita_us_dollar + output_data[output_data['country_name'] == 'Yemen: Former Yemen Arab Republic'].gni_per_capita_us_dollar) / 2\r\n",
        "  yemen_missing_gni_values.dropna(inplace = True)\r\n",
        "  yemen_df = pd.DataFrame(output_data[output_data['country_name'] == 'Yemen'].gni_per_capita_us_dollar.fillna(yemen_missing_gni_values))\r\n",
        "  yemen_df['country_name'] = 'Yemen'\r\n",
        "  yemen_df.reset_index(inplace = True)\r\n",
        "  yemen_df.set_index(['calendar_year', 'country_name'], inplace = True)\r\n",
        "  \r\n",
        "  # fill missing values of 'Yemen' with above computed values\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "  output_data.set_index(['calendar_year', 'country_name'], inplace = True)\r\n",
        "  output_data.fillna(yemen_df, inplace = True)\r\n",
        "\r\n",
        "  # reset index\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "  \r\n",
        "  # drop 'Yemen: Former Democratic Yemen' and 'Yemen: Former Yemen Arab Republic' due to consolidation\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Yemen: Former Democratic Yemen'].index, inplace = True)\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Yemen: Former Yemen Arab Republic'].index, inplace = True)\r\n",
        "  \r\n",
        "  # drop entries that still involve missing values is now safe \r\n",
        "  output_data.dropna(inplace = True)\r\n",
        "  output_data.reset_index(inplace = True, drop = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "income_data_preprocessed = fix_missing_gni_per_capita_values(income_data_population_total_complete)\r\n",
        "\r\n",
        "# check whether or not all missing values have been replaced\r\n",
        "sb.heatmap(income_data_preprocessed.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WucPBil7xQ8"
      },
      "source": [
        "## Load thresholds and sdr deflators\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYXSRiPrnGY"
      },
      "source": [
        "def load_thresholds_sdr_deflators():\r\n",
        "  \r\n",
        "  # load income-level thresholds\r\n",
        "  income_threshold_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/world_bank_income_level_thresholds.csv', sep = ',')\r\n",
        "  income_threshold_data.drop(['banks_fiscal_year'], axis = 1, inplace = True)\r\n",
        "\r\n",
        "  # load sdr deflator values\r\n",
        "  sdr_deflator_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/world_bank_sdr_deflator.csv', sep = ',')\r\n",
        "  sdr_deflator_data.drop(['sdr_deflator_us_dollar'], axis = 1, inplace = True)\r\n",
        "\r\n",
        "  # create index on calendar_year\r\n",
        "  income_threshold_data.set_index(['calendar_year'], inplace = True)\r\n",
        "  sdr_deflator_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  # merge income_threshold_data and sdr_deflator_data using index 'calendar_year'\r\n",
        "  output_data = income_threshold_data.merge(sdr_deflator_data, how = 'inner', left_index = True, right_index = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "threshold_data = load_thresholds_sdr_deflators()\r\n",
        "\r\n",
        "# visualize missing threshold values using a heatmap\r\n",
        "sb.heatmap(threshold_data[['low_income_level_threshold', 'middle_income_level_threshold', 'high_income_level_threshold']].isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOA-6HmO8Dbp"
      },
      "source": [
        "## Calculate missing thresholds using sdr deflators\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UprCduwpmDL9"
      },
      "source": [
        "def calculate_missing_thresholds(input_data):\r\n",
        "    \r\n",
        "    output_data = input_data.copy()\r\n",
        "    \r\n",
        "    thresholds_list = ['low_income_level_threshold', 'middle_income_level_threshold', 'high_income_level_threshold']   \r\n",
        "    \r\n",
        "    # calculate missing values\r\n",
        "    for row_index in range(0, len(output_data)):\r\n",
        "      \r\n",
        "      # retrieve current index\r\n",
        "      curr_index = output_data.index.max() - row_index\r\n",
        "      for threshold in thresholds_list:\r\n",
        "        \r\n",
        "        # check if threshold value is missing\r\n",
        "        if(np.isnan(output_data.loc[curr_index, threshold])):\r\n",
        "          \r\n",
        "          # calculate missing threshold value based on existing threshold and sdr_inflation_rate_annual_change\r\n",
        "          output_data.loc[curr_index, threshold] = output_data.loc[curr_index + 1, threshold] / (100 + output_data.loc[curr_index + 1, 'sdr_inflation_rate_annual_change']) * 100\r\n",
        "    \r\n",
        "    # round thresholds to nearest multiple of base\r\n",
        "    base = 5\r\n",
        "    for threshold in thresholds_list:\r\n",
        "      output_data[threshold] = round(output_data[threshold] / base) * base\r\n",
        "\r\n",
        "    return output_data[thresholds_list]\r\n",
        "\r\n",
        "threshold_data_preprocessed = calculate_missing_thresholds(threshold_data)\r\n",
        "\r\n",
        "# check whether or not all missing values have been replaced\r\n",
        "sb.heatmap(threshold_data_preprocessed.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkwUcixAG-QB"
      },
      "source": [
        "## Assign income-level labels based on gni and income-level thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KFdBCwxyjEn"
      },
      "source": [
        "def assign_income_level_labels(input_income_data, input_threshold_data):\r\n",
        "\r\n",
        "  # merge income_data_preprocessed and threshold_data_complete using calendar_year\r\n",
        "  output_data = input_income_data.merge(input_threshold_data, how = 'left', on = 'calendar_year')\r\n",
        "\r\n",
        "  # assign income-level labels based on gni and thresholds\r\n",
        "  output_data.loc[(output_data['gni_per_capita_us_dollar'] <= output_data['low_income_level_threshold']), 'income_level_label'] = 'low_income'\r\n",
        "  output_data.loc[((output_data['gni_per_capita_us_dollar'] > output_data['low_income_level_threshold']) & \r\n",
        "                          (output_data['gni_per_capita_us_dollar'] <= output_data['middle_income_level_threshold'])), 'income_level_label'] = 'lower_middle_income'\r\n",
        "  output_data.loc[((output_data['gni_per_capita_us_dollar'] > output_data['middle_income_level_threshold']) & \r\n",
        "                          (output_data['gni_per_capita_us_dollar'] <= output_data['high_income_level_threshold'])), 'income_level_label'] = 'upper_middle_income'\r\n",
        "  output_data.loc[(output_data['gni_per_capita_us_dollar'] > output_data['high_income_level_threshold']), 'income_level_label'] = 'high_income'\r\n",
        "\r\n",
        "  # create index on calendar_year\r\n",
        "  output_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "income_classification_data = assign_income_level_labels(income_data_preprocessed, threshold_data_preprocessed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bLAKKKQrfsG"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEgcKVdKUEIA"
      },
      "source": [
        "## Calculating the population living in the different income levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w6atxv7UPYA"
      },
      "source": [
        "def calculate_sum_population_per_income_level_and_year(input_data):\r\n",
        "\r\n",
        "  output_data = pd.DataFrame()\r\n",
        "\r\n",
        "  # create sum of population of each income category for each year\r\n",
        "  output_data['low_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'low_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['lower_middle_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'lower_middle_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['upper_middle_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'upper_middle_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['high_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'high_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['total_population'] = input_data['population_total'].groupby('calendar_year').sum()\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "population_income = calculate_sum_population_per_income_level_and_year(income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pAZB1E2vv_P"
      },
      "source": [
        "## Visualization of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYknZxtoajh_"
      },
      "source": [
        "# plot cumulative total population according to income-levels\r\n",
        "\r\n",
        "# select years to include in plot\r\n",
        "years = range(min(population_income.index), max(population_income.index))\r\n",
        "\r\n",
        "# calculate cumulative total_population according to income-levels\r\n",
        "low_income_cumulative = population_income.loc[population_income.index.isin(years), 'low_income_population'].values\r\n",
        "lower_middle_income_cumulative = low_income_cumulative + population_income.loc[population_income.index.isin(years), 'lower_middle_income_population'].values\r\n",
        "upper_middle_income_cumulative = lower_middle_income_cumulative + population_income.loc[population_income.index.isin(years), 'upper_middle_income_population'].values\r\n",
        "high_income_cumulative = upper_middle_income_cumulative + population_income.loc[population_income.index.isin(years), 'high_income_population'].values\r\n",
        "\r\n",
        "# create plot\r\n",
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "ax.plot(population_income['total_population'].groupby('calendar_year').max(), label = 'total_population', color = 'Black')\r\n",
        "ax.plot(population_income['total_population'].groupby('calendar_year').max() * 0.5, label = 'half_of_total_population', color = 'Red', linestyle = 'dashed')\r\n",
        "\r\n",
        "ax.fill_between(years ,upper_middle_income_cumulative, high_income_cumulative, alpha = 0.3)\r\n",
        "ax.fill_between(years ,lower_middle_income_cumulative, upper_middle_income_cumulative, alpha= 0.3)\r\n",
        "ax.fill_between(years, low_income_cumulative, lower_middle_income_cumulative, alpha = 0.3)\r\n",
        "ax.fill_between(years, low_income_cumulative, 0, alpha = 0.3)\r\n",
        "ax.text(1990, 1.5e9, 'low income', fontsize = 9, color = 'White')\r\n",
        "ax.text(1995, 3.5e9, 'lower_middle_income', fontsize = 9, color = 'White')\r\n",
        "ax.text(2003, 5e9, 'upper_middle_income', fontsize = 9, color = 'White')\r\n",
        "ax.text(2009, 6.5e9, 'high_income', fontsize = 9, color = 'White')\r\n",
        "\r\n",
        "ax.set_title('Visualizing historical development of world\\'s population according to different \\n income-levels based on the information of more than 160 countries', pad = 20)\r\n",
        "ax.set_xlabel('Calendar Year')\r\n",
        "ax.set_ylabel('World\\'s Population')\r\n",
        "\r\n",
        "plt.xlim([min(population_income.index), max(population_income.index) - 1])\r\n",
        "plt.ylim([0, population_income['total_population'].max()])\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u55r7_GksFzB"
      },
      "source": [
        "# plot income of the 5 largest countries \r\n",
        "\r\n",
        "# select years to include in plot\r\n",
        "years = range(min(population_income.index), max(population_income.index))\r\n",
        "\r\n",
        "# select 5 largest countries\r\n",
        "countries_most_populous = income_classification_data.loc[max(population_income.index)].nlargest(5,'population_total')['country_name'].values\r\n",
        "\r\n",
        "# extract income thresholds\r\n",
        "high_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['high_income_level_threshold'].values\r\n",
        "middle_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['middle_income_level_threshold'].values\r\n",
        "low_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['low_income_level_threshold'].values\r\n",
        "\r\n",
        "# create plot\r\n",
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  ax.plot(income_classification_data['gni_per_capita_us_dollar'].loc[income_classification_data['country_name'] == countries_most_populous[i]],label = countries_most_populous[i])\r\n",
        "\r\n",
        "plt.yscale('log')\r\n",
        "\r\n",
        "ax.fill_between(years,high_income_treshold, 1e5,alpha = 0.3)\r\n",
        "ax.fill_between(years,high_income_treshold, middle_income_treshold, alpha = 0.3)\r\n",
        "ax.fill_between(years,low_income_treshold, middle_income_treshold, alpha = 0.3)\r\n",
        "ax.fill_between(years,low_income_treshold, 0, alpha = 0.3)\r\n",
        "ax.text(2004, 1.5e2, 'low income', fontsize = 9, color = 'White')\r\n",
        "ax.text(1980, 1.3e3, 'lower_middle_income', fontsize = 9, color = 'White')\r\n",
        "ax.text(1990, 5e3, 'upper_middle_income', fontsize = 9, color = 'White')\r\n",
        "ax.text(2000, 2e4, 'high_income', fontsize = 9, color = 'White')\r\n",
        "\r\n",
        "ax.set_title('TODO', pad = 20)\r\n",
        "ax.set_xlabel('Calendar Year')\r\n",
        "ax.set_ylabel('log(GNI per Capita in US Dollar)')\r\n",
        "\r\n",
        "plt.xlim([min(population_income.index), max(population_income.index) - 1])\r\n",
        "plt.ylim([5e1,1e5])\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHWNQ7lxyvk"
      },
      "source": [
        "# show histogram of differtent income levels in 2018\r\n",
        "fig, ax = plt.subplots()\r\n",
        "income_classification_data['income_level_label'].loc[max(income_classification_data.index)].hist( grid = False)\r\n",
        "ax.set_title('Distribution of countries according to different income-levels', pad = 20)\r\n",
        "plt.xlabel('Income Levels')\r\n",
        "plt.ylabel('Number of Countries')\r\n",
        "\r\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_G9LRDcy3ml"
      },
      "source": [
        "# create df to show the sum of coutries for each income classification\r\n",
        "income_classification_count = income_classification_data['income_level_label'].groupby('calendar_year').value_counts(dropna = False)\r\n",
        "\r\n",
        "# plot total count of classification entries each year [sum of countries]\r\n",
        "fig, ax = plt.subplots()\r\n",
        "income_classification_total_count = income_classification_count[:,'high_income']+income_classification_count[:,'upper_middle_income']+income_classification_count[:,'lower_middle_income']+income_classification_count[:,'low_income']\r\n",
        "plt.plot(income_classification_total_count, label = 'total_classification_count', color = 'black')\r\n",
        "ax.set_title('TODO', pad = 20)\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of Countries')\r\n",
        "plt.xlim([min(income_classification_total_count.index), max(income_classification_total_count.index) - 1])\r\n",
        "plt.ylim([0, 200])\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbIbmagseQai"
      },
      "source": [
        "# wollt ihr die beiden plots drinnen lassen, glaub die sind recht schwer zu interpretieren? \r\n",
        "# plot income classification count over time\r\n",
        "plt.plot(population_income['high_income_population'], label = 'high_income' )\r\n",
        "plt.plot(population_income['upper_middle_income_population'], label = 'upper_middle_income')\r\n",
        "plt.plot(population_income['lower_middle_income_population'], label = 'lower_middle_income')\r\n",
        "plt.plot(population_income['low_income_population'], label = 'low_income')\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of People')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# income_classification_data =  income_classification_data.loc[income_classification_data['population_total'] > 1000000.0]\r\n",
        "# print(income_classification_data)\r\n",
        "# print(income_classification_data[['population_total', 'income_level_label']].groupby(['calendar_year', 'income_level_label']).sum().groupby('calendar_year').sum())\r\n",
        "\r\n",
        "# plot income classification count over time [sum of countries]\r\n",
        "plt.plot(income_classification_count[:,'high_income'], label = 'high_income' )\r\n",
        "plt.plot(income_classification_count[:,'upper_middle_income'], label = 'upper_middle_income')\r\n",
        "plt.plot(income_classification_count[:,'lower_middle_income'], label = 'lower_middle_income')\r\n",
        "plt.plot(income_classification_count[:,'low_income'], label = 'low_income')\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of Countries')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yghsEQkMNPlr"
      },
      "source": [
        "## Interactive world map (choropleth map)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrh3_7tl9pMV"
      },
      "source": [
        "def preprocessing_world_map_data(input_data):\r\n",
        "\r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop index on calendar_year\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "\r\n",
        "  former_country_lists = [['Former Czechoslovakia', 'Czech Republic', 'Slovakia'],\r\n",
        "                             ['Former Ethiopia', 'Ethiopia', 'Eritrea'],\r\n",
        "                             ['Former Sudan', 'Sudan', 'South Sudan'],\r\n",
        "                             ['Former USSR', 'Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', \r\n",
        "                              'Republic of Moldova', 'Russian Federation', 'Tajikistan', 'Turkmenistan', 'Ukraine', 'Uzbekistan'],\r\n",
        "                             ['Former Yugoslavia', 'Bosnia and Herzegovina', 'Croatia', 'Montenegro', 'Republic of North Macedonia', 'Serbia', 'Slovenia']]\r\n",
        "\r\n",
        "  for country_list in former_country_lists:\r\n",
        "\r\n",
        "    # get first list elem of list\r\n",
        "    former_country_name = country_list.pop(0)\r\n",
        "\r\n",
        "    # get list of calendar_years\r\n",
        "    calendar_year_list = output_data.loc[output_data['country_name'] == former_country_name].calendar_year.tolist()\r\n",
        "    \r\n",
        "    for calendar_year in calendar_year_list:\r\n",
        "\r\n",
        "      # get current index of former country at particular calender_year  \r\n",
        "      curr_former_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == former_country_name)].income_level_label.index.max()\r\n",
        "\r\n",
        "      # get income-level of former country\r\n",
        "      income_level_label = output_data.loc[curr_former_country_index, 'income_level_label']\r\n",
        "      \r\n",
        "      # get max calender year of dataframe\r\n",
        "      max_calendar_year = max(output_data['calendar_year'])\r\n",
        "\r\n",
        "      for country_name in country_list:\r\n",
        "        \r\n",
        "        # get current index of country at particular calender_year  \r\n",
        "        curr_country_index = output_data.loc[(output_data['calendar_year'] ==  max_calendar_year) & (output_data['country_name'] == country_name)].income_level_label.index.max()\r\n",
        "\r\n",
        "        # get income-level of former country\r\n",
        "        iso_alpha3_code = output_data.loc[curr_country_index, 'iso_alpha3_code']\r\n",
        "\r\n",
        "        # append row to dataframe\r\n",
        "        output_data = output_data.append({'calendar_year' : calendar_year, \r\n",
        "                                          'iso_alpha3_code' : iso_alpha3_code,\r\n",
        "                                          'country_name' :  country_name, \r\n",
        "                                          'income_level_label' : income_level_label} , ignore_index = True)\r\n",
        "\r\n",
        "  # set index on calendar_year\r\n",
        "  output_data.reset_index(inplace = True, drop = True)\r\n",
        "  output_data.sort_values(by = ['country_name', 'calendar_year'], inplace = True)\r\n",
        "  output_data.set_index('calendar_year', inplace = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "world_map_data = preprocessing_world_map_data(income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZeHmghtNOl7"
      },
      "source": [
        "@interact(selected_year = IntSlider(value = min(world_map_data.index), min = min(world_map_data.index), max = max(world_map_data.index)))\r\n",
        "def interactive_world_map_visualization_(selected_year):\r\n",
        "  \r\n",
        "  # load geometry data for all countries \r\n",
        "  world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\r\n",
        "\r\n",
        "  # correct wrong iso code\r\n",
        "  world.loc[world['name'] == 'France', 'iso_a3'] = 'FRA'\r\n",
        "  world.loc[world['name'] == 'Norway', 'iso_a3'] = 'NOR'\r\n",
        "  world.loc[world['name'] == 'Kosovo', 'iso_a3'] = 'XKX'\r\n",
        "\r\n",
        "  # drop unnecessary columns\r\n",
        "  country_shapes = world[['geometry', 'iso_a3']]\r\n",
        "\r\n",
        "  # merge geometry with income data on country code, select year to look at\r\n",
        "  geo_income_data = country_shapes.merge(world_map_data.loc[selected_year], left_on='iso_a3', right_on='iso_alpha3_code')\r\n",
        "\r\n",
        "  # plot map\r\n",
        "  legend_dict = {'bbox_to_anchor' : (1., 1), 'loc' :'upper left'}\r\n",
        "  colors = ['dodgerblue','maroon','lightcoral','skyblue']\r\n",
        "  geo_income_data.plot(column='income_level_label', legend = True, legend_kwds = legend_dict, figsize=(15, 10), cmap = matplotlib.colors.ListedColormap(colors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maNKqI1AYRo0"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co1-PW06YZyx"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99raLyMor7k"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7KcaJodYlwS"
      },
      "source": [
        "def load_world_bank_indicator_data():\r\n",
        "  # load indicator data from csv (World Bank Data)\r\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/data_indicators_2.csv', sep = ',', nrows = 16104)\r\n",
        "  data.replace('..',np.nan,inplace=True)\r\n",
        "\r\n",
        "  #rename columns\r\n",
        "  rename_columns_dict = {'Time':'calendar_year','Country Code':'iso_alpha3_code','Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]':'fertility_rate','Urban population (% of total population) [SP.URB.TOTL.IN.ZS]':'urban_population','Access to electricity (% of population) [EG.ELC.ACCS.ZS]':'access_electricity', 'Agriculture, forestry, and fishing, value added (% of GDP) [NV.AGR.TOTL.ZS]':'agriculture_forestry_fishing_sector','Unemployment, total (% of total labor force) (modeled ILO estimate) [SL.UEM.TOTL.ZS]':'unemployment', 'Total natural resources rents (% of GDP) [NY.GDP.TOTL.RT.ZS]':'natural_resources_rent','Inflation, consumer prices (annual %) [FP.CPI.TOTL.ZG]':'inflation','External balance on goods and services (% of GDP) [NE.RSB.GNFS.ZS]':'external_balance_on_goods_and_services','School enrollment, primary (% gross) [SE.PRM.ENRR]':'primary_school_enrollment','Life expectancy at birth, total (years) [SP.DYN.LE00.IN]':'life_expectancy'}\r\n",
        "  data.rename(rename_columns_dict, axis='columns',inplace=True)\r\n",
        "\r\n",
        "  #only use Data from 2013-2018\r\n",
        "  data = data[data['calendar_year'].isin(range(2013,2019))]\r\n",
        "\r\n",
        "  # select only ceratain parameters (drop columns with very few entries)\r\n",
        "  data = data[['calendar_year','iso_alpha3_code','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']]\r\n",
        "\r\n",
        "  #change data types of columns\r\n",
        "  data = data.astype({'fertility_rate': float, 'urban_population': float, 'access_electricity': float, 'agriculture_forestry_fishing_sector': float, 'inflation': float, 'external_balance_on_goods_and_services': float, 'natural_resources_rent': float, 'life_expectancy': float})\r\n",
        "\r\n",
        "  return data\r\n",
        "\r\n",
        "indicator_data = load_world_bank_indicator_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGjAsIo9o0hm"
      },
      "source": [
        "### Merge with Data from Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxHHmiKfomPz"
      },
      "source": [
        "def merge_indicator_and_income_data(indicator, income):\r\n",
        "  income.reset_index(inplace =True)\r\n",
        "  merged_data = income.merge(indicator, how = 'inner', on = ['calendar_year','iso_alpha3_code'])\r\n",
        "\r\n",
        "  #set index \r\n",
        "  merged_data.set_index(['calendar_year','country_name'], inplace = True)\r\n",
        "\r\n",
        "  return merged_data\r\n",
        "\r\n",
        "indicator_income_data = merge_indicator_and_income_data(indicator_data, income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhqE30CwwyJa"
      },
      "source": [
        "### Deal with missing data and outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd0_tKnjw5M2"
      },
      "source": [
        "sb.heatmap(indicator_income_data.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DutppAFdHLF"
      },
      "source": [
        "def clean_data(input_data):\r\n",
        "\r\n",
        "  #delete data entries with inflation over 30 % . Ignore hyperinflation in Sudan, Venezuela, etc...\r\n",
        "  output_data= input_data.loc[indicator_income_data['inflation']<25]\r\n",
        "\r\n",
        "  #remove specified countries that have very few data available\r\n",
        "  drop_countries_list = ['AND', 'CYM','MCO', 'SMR', 'TCA', 'ERI','PRK','SOM']\r\n",
        "  output_data = output_data[output_data['iso_alpha3_code'].isin(drop_countries_list) == False]\r\n",
        "\r\n",
        "  # fill the missing agriculture_forestry_fishing_sector values in 2017 and 2018 in Canada with the value from the year 2016. \r\n",
        "  output_data.loc[([2017,2018],'Canada'),'agriculture_forestry_fishing_sector'] = 1.862226\t\r\n",
        "\r\n",
        "  # fill the missing agriculture_forestry_fishing_sector values in  2018 in New Zealand with the value from the year 2017. \r\n",
        "  output_data.loc[([2018],'New Zealand'),'agriculture_forestry_fishing_sector'] = 5.814862\t\r\n",
        "\r\n",
        "  # The parameter agriculture_forestry_fishing_sector does not change rapidly and therfore filling it with the last known value should be justified for Canada and New Zealand. Only 1 or 2 years missing\r\n",
        "\r\n",
        "  # fill the missing agriculture_forestry_fishing_sector values for Macau with zero. \r\n",
        "  output_data.loc[([2013,2014,2015,2016,2017,2018],'China, Macao Special Administrative Region'),'agriculture_forestry_fishing_sector'] = 0\t\r\n",
        "\r\n",
        "  #no agriculture_forestry_fishing_sector data was available in the data of the world bank. Macau is a very small urban area with nearly no agriculture_forestry_fishing_sector.  https://www.indexmundi.com/macau/economy_profile.html\r\n",
        "  #Remove all countries with missing external_balance_on_goods_and_services or agriculture_forestry_fishing_sector data\r\n",
        "  output_data.dropna(subset = ['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy'],inplace = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "\r\n",
        "indicator_income_data_cleaned = clean_data(indicator_income_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQ7I5iaKq37"
      },
      "source": [
        "indicator_income_data_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buSNbsD_PrwE"
      },
      "source": [
        "### Deal with outlieres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkM36SzjPuQm"
      },
      "source": [
        "#indicator_income_data[(indicator_income_data['urban_population']<40) & (indicator_income_data['gni_per_capita_us_dollar']>1e4)]\r\n",
        "\r\n",
        "#Liechtenstein is a big outlier regarding the low urban population and the big gni and also a very small country (Was clearly visible in scatter plots). Therfore it is droped for our algorithm ?????\r\n",
        "#indicator_income_data.drop('Liechtenstein', level='country_name', inplace=True)\r\n",
        "\r\n",
        "# Uni-variate outlier analysis\r\n",
        "# Discovering outliers with visualization tool Box plot\r\n",
        "\r\n",
        "fig, axs = plt.subplots(2,4)\r\n",
        "axs[0,0].boxplot(indicator_income_data_cleaned['fertility_rate'])\r\n",
        "axs[0,0].set_title('fertility_rate')\r\n",
        "axs [0,1].boxplot(indicator_income_data_cleaned['urban_population'])\r\n",
        "axs [0,1].set_title('urban_population')\r\n",
        "axs[0,2].boxplot(indicator_income_data_cleaned['access_electricity'])\r\n",
        "axs[0,2].set_title('access_electricity')\r\n",
        "axs [0,3].boxplot(indicator_income_data_cleaned['agriculture_forestry_fishing_sector'])\r\n",
        "axs [0,3].set_title('agriculture_forestry_fishing_sector')\r\n",
        "axs[1,0].boxplot(indicator_income_data_cleaned['external_balance_on_goods_and_services'])\r\n",
        "axs[1,0].set_title('external_balance_on_goods_and_services')\r\n",
        "axs [1,1].boxplot(indicator_income_data_cleaned['natural_resources_rent'])\r\n",
        "axs [1,1].set_title('natural_resources_rent')\r\n",
        "axs[1,2].boxplot(indicator_income_data_cleaned['inflation'])\r\n",
        "axs[1,2].set_title('inflation')\r\n",
        "axs [1,3].boxplot(indicator_income_data_cleaned['life_expectancy'])\r\n",
        "axs [1,3].set_title('life_expectancy1')\r\n",
        "\r\n",
        "fig.subplots_adjust(left=0.08, right=0.98, bottom=0.05, top=0.9,\r\n",
        "                    hspace=0.6, wspace=0.6)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1deWVmqAcv5"
      },
      "source": [
        "# Discovering outliers with mathematical function\n",
        "\n",
        "# Z-score\n",
        "# With Z-score we re-scale and center the data and look for data points which are too far from zero. Data points which are too far from zero will be treated as outliers.\n",
        "# In the most cases a threshold of 3 or -3 is used. Z-score values greater than or less than 3 or -3 respectively is an outlier.\n",
        "\n",
        "# Function to compute z-score \n",
        "z = np.abs(stats.zscore(indicator_income_data_cleaned[['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']]))\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "# defining threshold\n",
        "threshold = 3\n",
        "\n",
        "# The first array contains the list of row numbers and the second array respective column numbers\n",
        "print(np.where(z > 3))\n",
        "# z[48][6] has a z-score higher than 3.\n",
        "print(z[48][6])\n",
        "print(z.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyjNGIGEFgrA"
      },
      "source": [
        "# exploring outliers\n",
        "\n",
        "print(indicator_income_data_cleaned.iloc[49,:])\n",
        "\n",
        "ab = indicator_income_data_cleaned.iloc[indicator_income_data_cleaned.index.get_level_values('country_name') == 'Belarus']\n",
        "print(ab['inflation'])\n",
        "\n",
        "# Filter the outliers using Z-score\n",
        "#indicator_income_data_out = indicator_income_data_cleaned['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy'](z > 3)]\n",
        "#print(indicator_income_data_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUQw2JJBeRb8"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbihL2eKwedV"
      },
      "source": [
        "sb.heatmap(indicator_income_data_cleaned.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aANwuQjg3apf"
      },
      "source": [
        "sb.countplot(indicator_income_data_cleaned['income_level_label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0qh4WJyUsX-"
      },
      "source": [
        "def plot_scatter_matrix(input_data):\r\n",
        "  # Scatterplot Matrix\r\n",
        "  sm = pd.plotting.scatter_matrix(input_data[['income_level_label','gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']], figsize=(18, 18), diagonal='hist')\r\n",
        "  #Change label rotation\r\n",
        "  [s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]\r\n",
        "  [s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]\r\n",
        "  #May need to offset label when rotating to prevent overlap of figure\r\n",
        "  [s.get_yaxis().set_label_coords(-0.6,0.5) for s in sm.reshape(-1)]\r\n",
        "  #Hide all ticks\r\n",
        "  [s.set_xticks(()) for s in sm.reshape(-1)]\r\n",
        "  [s.set_yticks(()) for s in sm.reshape(-1)]\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "plot_scatter_matrix(indicator_income_data_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYpGEobg8FYw"
      },
      "source": [
        "def plot_gni_scatter_plot(scatter_data):\r\n",
        "\r\n",
        "  #plot scatter plot with colorized classification and logarithmic scale for gni per capita\r\n",
        "\r\n",
        "  #create income level number\r\n",
        "  # low_income = 1\r\n",
        "  # lower_middle_income = 2\r\n",
        "  # upper_middle_income = 3\r\n",
        "  # high_income = 4\r\n",
        "\r\n",
        "  scatter_data['income_classification_number'] = np.nan\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'low_income', 'income_classification_number'] = 1\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'lower_middle_income',['income_classification_number']] = 2\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'upper_middle_income',['income_classification_number']] = 3\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'high_income',['income_classification_number']] = 4\r\n",
        "\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['fertility_rate'], scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c = scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('fertility_rate')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['urban_population'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('urban_population')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['access_electricity'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('access_electricity')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['agriculture_forestry_fishing_sector'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('agriculture_forestry_fishing_sector')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['inflation'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('inflation')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['external_balance_on_goods_and_services'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'].values,s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('external_balance_on_goods_and_services')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['natural_resources_rent'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('natural_resources_rent')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['life_expectancy'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('life_expectancy')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "plot_gni_scatter_plot(indicator_income_data_cleaned)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnO2os3HuLOw"
      },
      "source": [
        "def plot_correlation_matrix(input_data):\r\n",
        "  # Full correlation matrix\r\n",
        "\r\n",
        "  colum_names = ['income_level_label','gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']\r\n",
        "  # Correlation matrix\r\n",
        "  correlations = input_data[['income_level_label','gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']].corr()\r\n",
        "  # Plot figsize\r\n",
        "  fig, ax = plt.subplots(figsize=(10, 10))\r\n",
        "  # Generate Color Map\r\n",
        "  colormap = sb.diverging_palette(220, 10, as_cmap=True)\r\n",
        "  # Generate Heat Map, allow annotations and place floats in map\r\n",
        "  sb.heatmap(correlations, cmap=colormap, annot=True, fmt=\".2f\")\r\n",
        "  ax.set_xticklabels(\r\n",
        "      colum_names,\r\n",
        "      rotation=45,\r\n",
        "      horizontalalignment='right'\r\n",
        "  );\r\n",
        "  ax.set_yticklabels(colum_names);\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "plot_correlation_matrix(indicator_income_data_cleaned)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ7WDLvKrhFR"
      },
      "source": [
        "# ML Algorithmus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkAHNebSrj7s"
      },
      "source": [
        "from sklearn import model_selection\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x96HaVwilXHB"
      },
      "source": [
        "# 20 selected countries( selection s.t. Training/Test set (20 countries) 5 countries per class 1,2,3,4 ... Gleiche Verteilung) \r\n",
        "twenty_countries = ['USA','CHL','AUT','BHR','ISR','TUR','COL','CHN','BRA','AZE','NGA','IND','BOL','CIV','EGY','AFG','BEN','TCD','BFA','CMR']  \r\n",
        "parameters = ['fertility_rate', 'urban_population', 'access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','life_expectancy','income_level_label']\r\n",
        "\r\n",
        "indicator_income_data_cleaned.reset_index(inplace = True)\r\n",
        "indicator_income_data_cleaned.set_index(['calendar_year','country_name'], inplace = True)\r\n",
        "\r\n",
        "pd.set_option('display.max_rows', None)\r\n",
        "pd.set_option('display.max_columns', None)\r\n",
        "\r\n",
        "indicator_income_data_cleaned['iso_alpha3_code'] = indicator_income_data_cleaned['iso_alpha3_code'].astype('string')\r\n",
        "\r\n",
        "#indicator_income_data_sel = indicator_income_data_cleaned[indicator_income_data_cleaned['iso_alpha3_code'].isin(twenty_countries)]\r\n",
        "indicator_income_data_sel = indicator_income_data_cleaned\r\n",
        "\r\n",
        "#leave only parameters (colums) of interest:\r\n",
        "indicator_income_data_sel = indicator_income_data_sel[parameters]\r\n",
        "\r\n",
        "indicator_income_data_sel_2014 = indicator_income_data_sel.loc[2014]\r\n",
        "indicator_income_data_sel_2015 = indicator_income_data_sel.loc[2015]\r\n",
        "indicator_income_data_sel_2016 = indicator_income_data_sel.loc[2016]\r\n",
        "indicator_income_data_sel_2017 = indicator_income_data_sel.loc[2017]\r\n",
        "indicator_income_data_sel_2018 = indicator_income_data_sel.loc[2018]\r\n",
        "\r\n",
        "indicator_income_data_sel_2014.head(25)\r\n",
        "#indicator_income_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhrVZoCqifc0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO-BH1WMzlor"
      },
      "source": [
        "# EXPLORE \r\n",
        "\r\n",
        "# Histogram of the class distribution\r\n",
        "#print (min(y),max(y))\r\n",
        "#y.hist(bins=6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT8c9z7lzyiN"
      },
      "source": [
        "# Histogram of the feature distributions\r\n",
        "#X.hist(bins=10,figsize=(10,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkWjqdqm0S4p"
      },
      "source": [
        "# Print the correlation coefficient of each feature with the class\r\n",
        "corr_matrix = indicator_income_data_sel_2014.corr()\r\n",
        "#print(corr_matrix['income_classification_number'].sort_values())\r\n",
        "\r\n",
        "## So, population_total is not a factor in the income level. Can be left out as parameter."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQKOtaz11MCl"
      },
      "source": [
        "# Full correlation matrix\r\n",
        "\r\n",
        "colum_names = parameters\r\n",
        "# Correlation matrix\r\n",
        "correlations = indicator_income_data_sel_2014.corr()\r\n",
        "# Plot figsize\r\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\r\n",
        "# Generate Color Map\r\n",
        "colormap = sns.diverging_palette(220, 10, as_cmap=True)\r\n",
        "# Generate Heat Map, allow annotations and place floats in map\r\n",
        "sns.heatmap(correlations, cmap=colormap, annot=True, fmt=\".2f\")\r\n",
        "ax.set_xticklabels(\r\n",
        "    colum_names,\r\n",
        "    rotation=45,\r\n",
        "    horizontalalignment='right'\r\n",
        ");\r\n",
        "ax.set_yticklabels(colum_names);\r\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlRpgGpa_CkB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsrfkpVe10fO"
      },
      "source": [
        "# Scatterplot Matrix\r\n",
        "sm = pd.plotting.scatter_matrix(indicator_income_data_sel_2014, figsize=(18, 18), diagonal='hist')\r\n",
        "#Change label rotation\r\n",
        "[s.xaxis.label.set_rotation(40) for s in sm.reshape(-1)]\r\n",
        "[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]\r\n",
        "#May need to offset label when rotating to prevent overlap of figure\r\n",
        "[s.get_yaxis().set_label_coords(-0.6,0.5) for s in sm.reshape(-1)]\r\n",
        "#Hide all ticks\r\n",
        "[s.set_xticks(()) for s in sm.reshape(-1)]\r\n",
        "[s.set_yticks(()) for s in sm.reshape(-1)]\r\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2UAUW352C8O"
      },
      "source": [
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmD6YEe5-pxV"
      },
      "source": [
        "  # set random seed in order to ensure reproducible results\r\n",
        "  np.random.seed(20210112)\r\n",
        "  rnd = np.random.randint(0,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9sfvdAxqnv"
      },
      "source": [
        "def separate_training_test_data(input_data, rnd):\r\n",
        "\r\n",
        "  # retrieve number of columns of input_data\r\n",
        "  n_cols = len(input_data.columns)\r\n",
        "  \r\n",
        "  # split up input_data into features and targets\r\n",
        "  features = input_data.reset_index().iloc[:, 1:n_cols].values\r\n",
        "  targets = input_data.reset_index().iloc[:, n_cols:(n_cols+1)].values.reshape(-1)\r\n",
        "\r\n",
        "  # separate training and test data with test_size = 0.2\r\n",
        "  features_train, features_test, targets_train, targets_test = train_test_split(features, targets, test_size = 0.2, random_state = rnd)\r\n",
        "\r\n",
        "  return features_train, features_test, targets_train, targets_test\r\n",
        "\r\n",
        "features_train, features_test, targets_train, targets_test = separate_training_test_data(indicator_income_data_sel_2014, rnd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZk2Qlzh0h2X"
      },
      "source": [
        "def perform_random_forest_classification(features, targets, rnd):\r\n",
        "\r\n",
        "  # build classification model based on random forest\r\n",
        "  rfcl = RandomForestClassifier(n_estimators = 50, random_state = rnd) \r\n",
        "\r\n",
        "  # set k and initialize cross-validation settings\r\n",
        "  k = 10\r\n",
        "  cv = KFold(n_splits = k, random_state = rnd, shuffle = True)\r\n",
        "\r\n",
        "  scores = []\r\n",
        "\r\n",
        "  # perform train-/validation-split\r\n",
        "  for train_index, validation_index in cv.split(features):\r\n",
        "    \r\n",
        "    features_train, features_validation = features[train_index], features[validation_index]\r\n",
        "    targets_train, targets_validation = targets[train_index], targets[validation_index]\r\n",
        "    \r\n",
        "    # fit to random forest classification model\r\n",
        "    rfcl.fit(features_train, targets_train)\r\n",
        "    \r\n",
        "    # compute score that compares predictions of model with true values of \r\n",
        "    scores.append(rfcl.score(features_validation, targets_validation))\r\n",
        "\r\n",
        "  print('mean accuracy (train-validate): ', mean(scores))\r\n",
        "\r\n",
        "  return rfcl\r\n",
        "\r\n",
        "random_forest_classifier = perform_random_forest_classification(features_train, targets_train, rnd)\r\n",
        "print('mean accuracy (test): ', random_forest_classifier.score(features_test, targets_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuVMWKX82AOP"
      },
      "source": [
        "# SPLIT DATA FOR TRAINING AND TESTING\r\n",
        "\r\n",
        "# Separate dataset as feature variables (unsere Parameter) and response variable (income_level_label)\r\n",
        "X = indicator_income_data_sel_2014[parameters].values\r\n",
        "y = indicator_income_data_sel_2014.income_level_label.values\r\n",
        "\r\n",
        "# Split into Traindata and Testdata\r\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=50) #80/20 split\r\n",
        "#y\r\n",
        "\r\n",
        "#bins = (1,2,3,4,5) # # of bins muss # labels(klassen) + 1 sein\r\n",
        "#labels = ['low','med_low','med_high','high']\r\n",
        "#y_train = pd.cut(y_train, bins = bins, labels = labels)\r\n",
        "#y_test = pd.cut(y_test, bins = bins, labels = labels)\r\n",
        "\r\n",
        "#sns.countplot(y_test)\r\n",
        "#plt.show()\r\n",
        "\r\n",
        "#print(y_train)\r\n",
        "#print(y_test)\r\n",
        "\r\n",
        "#create and fit the model\r\n",
        "rfcl = RandomForestClassifier(n_estimators=50) \r\n",
        "\r\n",
        "rfcl.fit(X_train, y_train)\r\n",
        "rfcl.score(X_test,y_test)\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "kf = KFold(n_splits=3)\r\n",
        "#kf\r\n",
        "\r\n",
        "for train_index, test_index in kf.split(X):\r\n",
        "  print(train_index, test_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqC69_FE2UNp"
      },
      "source": [
        "# measure performance\r\n",
        "\r\n",
        "def get_score(model, X_train, X_test, y_train, y_test):\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  return model.score(X_test, y_test)\r\n",
        "\r\n",
        "get_score(RandomForestClassifier(), X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmrIP9bG_qZK"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold #dasselbe wie KFold, nur hier werden Kategorien(low,med,..) Uniform verteilt.\r\n",
        "\r\n",
        "folds = StratifiedKFold(n_splits=3)\r\n",
        "\r\n",
        "scores_rf = []\r\n",
        "\r\n",
        "for train_index, test_index in folds.split(X,y):\r\n",
        "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\r\n",
        "  scores_rf.append(get_score(RandomForestClassifier(100), X_train, X_test, y_train, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlrSlWguDLig"
      },
      "source": [
        "scores_rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bECI3baDYkw"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score #cross_val_score verwendet stratified kfold\r\n",
        "\r\n",
        "cross_val_score(RandomForestClassifier(n_estimators=50),X, y, cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2KjVo9SFJb2"
      },
      "source": [
        "# Parameter tuning mit kfold cross validation\r\n",
        "\r\n",
        "scores1 = cross_val_score(RandomForestClassifier(n_estimators=5),X, y, cv=10)\r\n",
        "np.average(scores1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UstBl-x6FdQc"
      },
      "source": [
        "scores2 = cross_val_score(RandomForestClassifier(n_estimators=20),X, y, cv=10)\r\n",
        "np.average(scores2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdlSHd1HFjAd"
      },
      "source": [
        "scores3 = cross_val_score(RandomForestClassifier(n_estimators=30),X, y, cv=10)\r\n",
        "np.average(scores3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMgDRm8AFm7H"
      },
      "source": [
        "scores4 = cross_val_score(RandomForestClassifier(n_estimators=40),X, y, cv=10)\r\n",
        "np.average(scores4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dopp_2020w_group03_ex3_with_git.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_n-eLlFeXXOH",
        "7sqVqK8YHeSS"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoph-fraller/dopp_2020w_group03_ex3/blob/main/dopp_2020w_group03_ex3_with_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n-eLlFeXXOH"
      },
      "source": [
        "# Generate SSH-Keys for Accessing Git Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMNYj7F2o5Fz"
      },
      "source": [
        "# import and mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_vOiBlVR6Of"
      },
      "source": [
        "# generate ssh keys (insert your username@github.com + hit enter when prompted for any answer)\r\n",
        "! ssh-keygen -t rsa -b 4096 -C 'christoph.fraller@gmail.com'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLYpBS4KYhhf"
      },
      "source": [
        "# check whether or not the ssh keys have been created ('id_rsa' and 'id_rsa.pub' should be displayed)\r\n",
        "! ls /root/.ssh/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rx2E_IgUraa"
      },
      "source": [
        "# create directory for saving the ssh keys\r\n",
        "! mkdir -p /content/drive/MyDrive/Ssh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucFTIsSEVeZ0"
      },
      "source": [
        "# copy ssh keys from /root/.ssh/* to /content/drive/MyDrive/Ssh/*\r\n",
        "! cp /root/.ssh/id_rsa /content/drive/MyDrive/Ssh/\r\n",
        "! cp /root/.ssh/id_rsa.pub /content/drive/MyDrive/Ssh/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekNM8je8SefW"
      },
      "source": [
        "# display public ssh key for copy/paste\r\n",
        "! cat /content/drive/MyDrive/Ssh/id_rsa.pub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqNlD7pxTI6I"
      },
      "source": [
        "# add github to known hosts and adapt file access permissions\r\n",
        "! ssh-keyscan github.com >> /root/.ssh/known_hosts\r\n",
        "! chmod 644 /root/.ssh/known_hosts\r\n",
        "! chmod 600 /root/.ssh/id_rsa\r\n",
        "! ssh -T git@github.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sqVqK8YHeSS"
      },
      "source": [
        "# Git Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57DJRGnO5B0"
      },
      "source": [
        "# git config settings (replace with your credentials)\r\n",
        "! git config --global user.email \"maximilian.loesch97@gmail.com\"\r\n",
        "! git config --global user.name \"Maxiking1997\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEkuNsHeC8bF"
      },
      "source": [
        "# create directory for git repositories\r\n",
        "! mkdir -p /content/drive/MyDrive/Git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgI7KaUuVyPG"
      },
      "source": [
        "# git-clone has to be performed only once when setting up the git repo at your google drive\r\n",
        "! git clone git@github.com:christoph-fraller/dopp_2020w_group03_ex3.git /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb6rrvXMI4i_"
      },
      "source": [
        "## Important Shell and Git Commands\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDb8FOn5JC2h"
      },
      "source": [
        "**NOTICE:** Always ensure that you are in the right directory when performing git commands (e.g. /content/drive/MyDrive/Git/dopp_2020w_group03_ex3). In case of any issues that might occur when switching directories it is highly recommended to restart the runtime engine (CTRL + M + .)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GibAYNQjLDed"
      },
      "source": [
        "# check current working directory\r\n",
        "! pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6F2toRiJ1yE"
      },
      "source": [
        "# switch to specified working directory\r\n",
        "%cd /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKxY_7fJuRC"
      },
      "source": [
        "# list content of current working directory\r\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuJokwbqLMdf"
      },
      "source": [
        "# check git status\r\n",
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViV1YHxQLQZH"
      },
      "source": [
        "# always perform a git pull before you start working or commit/push some changes\r\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXfdcdIXOTk7"
      },
      "source": [
        "# add a new data file to git repo directly from colab\r\n",
        "# at first upload the file into the folder of your google drive \r\n",
        "! git add data/CPI-2005.csv\r\n",
        "! git commit -m 'New file added.'\r\n",
        "! git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SZJVIvmWrVe"
      },
      "source": [
        "# Perform these steps everytime when a new session has been started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOh292DlLnbG"
      },
      "source": [
        "# import and mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox9qElcvxY8p"
      },
      "source": [
        "# create directory\r\n",
        "! mkdir -p /root/.ssh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnKkBeH7Ww_B"
      },
      "source": [
        "# copy ssh keys from /content/drive/MyDrive/Ssh/* to /root/.ssh/*\r\n",
        "! cp /content/drive/MyDrive/Ssh/id_rsa /root/.ssh/\r\n",
        "! cp /content/drive/MyDrive/Ssh/id_rsa.pub /root/.ssh/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD1i__xSX8s4"
      },
      "source": [
        "# add github to known hosts and adapt file access permissions\r\n",
        "! ssh-keyscan github.com >> /root/.ssh/known_hosts\r\n",
        "! chmod 644 /root/.ssh/known_hosts\r\n",
        "! chmod 600 /root/.ssh/id_rsa\r\n",
        "! ssh -T git@github.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrMtv6CAyFAx"
      },
      "source": [
        "# switch to specified working directory\r\n",
        "%cd /content/drive/MyDrive/Git/dopp_2020w_group03_ex3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e75ezFO2XS4_"
      },
      "source": [
        "# always perform a git pull before you start working or commit/push some changes\r\n",
        "! git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4898HwMCGar"
      },
      "source": [
        "# Geopandas installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkUXPXQlCQX1"
      },
      "source": [
        "# Important library for many geopython libraries\r\n",
        "!apt install gdal-bin python-gdal python3-gdal \r\n",
        "# Install rtree - Geopandas requirment\r\n",
        "!apt install python3-rtree \r\n",
        "# Install Geopandas\r\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\r\n",
        "# Install descartes - Geopandas requirment\r\n",
        "!pip install descartes \r\n",
        "# Install Folium for Geographic data visualization\r\n",
        "!pip install folium\r\n",
        "# Install plotlyExpress\r\n",
        "!pip install plotly_express"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4PMn1CYaWbu"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sb\r\n",
        "import geopandas\r\n",
        "from ipywidgets import IntSlider, interact\r\n",
        "from scipy import stats\r\n",
        "from statistics import mean\r\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\r\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAa8Euy1xZYT"
      },
      "source": [
        "# Preprocessing of Income Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9p9vTpUxlrp"
      },
      "source": [
        "## Load and merge income data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-clO4Ga8bOK"
      },
      "source": [
        "def load_merge_income_data():\r\n",
        "  \r\n",
        "  # load income data from csv\r\n",
        "  income_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/undata_gni_per_capita.csv', sep = ';')\r\n",
        "\r\n",
        "  # extend income data by adding an entry for each combination of (calendar_year, country_code) due to there are currently no missing entries in the data\r\n",
        "  country_data_list = income_data[['country_code', 'country_name']].drop_duplicates().values.tolist()\r\n",
        "  output_list = []\r\n",
        "  for lst in country_data_list:\r\n",
        "      country_code = lst[0]\r\n",
        "      country_name = lst[1]\r\n",
        "      for calendar_year in range(1970, 2019):\r\n",
        "        output_list.append([calendar_year, country_code, country_name])\r\n",
        "  df = pd.DataFrame(output_list, columns = ['calendar_year', 'country_code', 'country_name'])\r\n",
        "  income_data_complete = df.merge(income_data[['calendar_year', 'country_code', 'gni_per_capita_us_dollar']], how = 'left', on = ['calendar_year', 'country_code'])\r\n",
        "\r\n",
        "  # load population data from csv\r\n",
        "  population_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/undata_population_total.csv', sep = ';', \r\n",
        "                                usecols = ['country_code', 'calendar_year', 'population_total'])\r\n",
        "  population_data.drop_duplicates(inplace = True)\r\n",
        "  population_data['population_total'] = population_data['population_total'] * 1000 # total population is specified in 1000\r\n",
        "\r\n",
        "  # load country codes from csv\r\n",
        "  country_codes = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/iso3166_unsd_country_codes.csv', sep = ';', \r\n",
        "                              usecols = ['m49_code', 'iso_alpha2_code', 'iso_alpha3_code', 'small_island_developing_states'])\r\n",
        "\r\n",
        "  # merge income with population data and country codes\r\n",
        "  output_data = income_data_complete.merge(population_data, how = 'left', on = ['calendar_year', 'country_code'])\r\n",
        "  output_data = output_data.merge(country_codes, how = 'left', left_on = 'country_code', right_on = 'm49_code')\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "merged_income_data = load_merge_income_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcwPvGpE-xpZ"
      },
      "source": [
        "## Clean issues in income data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRAd80L-3vC0"
      },
      "source": [
        "def clean_income_data(input_data):\r\n",
        "  \r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop duplicate information at column-level\r\n",
        "  output_data.drop(['country_code'], axis = 1, inplace = True)\r\n",
        "  output_data.rename(columns = {'country_code': 'm49_code'}, inplace = True) \r\n",
        "\r\n",
        "  # replace values of column 'small_island_developing_states' by True/False\r\n",
        "  output_data['small_island_developing_states'].replace('x', True, inplace = True)\r\n",
        "  output_data['small_island_developing_states'].fillna(False, inplace = True)\r\n",
        "\r\n",
        "  # fix issues at column 'small_island_developing_states' for some countries\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'Former Netherlands Antilles'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'United Republic of Tanzania: Mainland'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "  output_data.iloc[output_data[output_data['country_name'] == 'United Republic of Tanzania: Zanzibar'].index, output_data.columns.get_loc('small_island_developing_states')] = True\r\n",
        "\r\n",
        "  # drop small island countries and reset row index\r\n",
        "  output_data.drop(output_data[output_data['small_island_developing_states'] == True].index, inplace = True)\r\n",
        "  output_data.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  # reorder colums of dataframe\r\n",
        "  output_data = output_data[['calendar_year', 'iso_alpha3_code', 'iso_alpha2_code', 'm49_code', 'country_name', 'population_total', 'gni_per_capita_us_dollar']]\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "cleaned_income_data = clean_income_data(merged_income_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrR6-ZxGAfJh"
      },
      "source": [
        "## Exploring missing values in income data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jKXCYG-Al7g"
      },
      "source": [
        "# get an overview of missing values in income data\r\n",
        "# it seems there is pattern between the missing values of the columns iso_alpha3_code, iso_alpha2_code, m49_code and population_total\r\n",
        "ax = plt.axes()\r\n",
        "sb.heatmap(cleaned_income_data.isna(), cbar = False);\r\n",
        "ax.set_title('Visualization of missing values in income dataset')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3AL9oR7BUjL"
      },
      "source": [
        "# ad 1) missing values in country codes\r\n",
        "# obtain countries with missing country codes (iso_alpha3_code, iso_alpha2_code, m49_code)\r\n",
        "iso_alpha3_code_set = set(cleaned_income_data.loc[cleaned_income_data['iso_alpha3_code'].isna()].country_name.unique().tolist())\r\n",
        "iso_alpha2_code_set = set(cleaned_income_data.loc[cleaned_income_data['iso_alpha2_code'].isna()].country_name.unique().tolist())\r\n",
        "m49_code_set = set(cleaned_income_data.loc[cleaned_income_data['m49_code'].isna()].country_name.unique().tolist())\r\n",
        "union_list_sorted = sorted(iso_alpha3_code_set | iso_alpha2_code_set | m49_code_set)\r\n",
        "print('\\nCountries with missing entries in their country codes:')\r\n",
        "print('------------------------------------------------------')\r\n",
        "print(*union_list_sorted, sep = '\\n')\r\n",
        "\r\n",
        "# strategy on dealing with missing in country codes:\r\n",
        "\r\n",
        "## most of the missing entries in country codes can be traced back to former countries that no longer exist and therefore their codes are missing in \r\n",
        "## the actual iso3166 standard but in order to obtain a complete dataset we will refill based on historical data: Former Czechoslovakia, Former Ethiopia,\r\n",
        "## Former Sudan, Former USSR, Former Yugoslavia, Yemen: Former Democratic Yemen, Yemen: Former Yemen Arab Republic\r\n",
        "\r\n",
        "## Nambia's iso_alpha2_code corresponds to 'NA', which is interpreted as NA per default, we have to fix this when inserting the other missing country codes\r\n",
        "\r\n",
        "## Kosovo has declared its independence from Serbia in 2008 but until today this declaration is quite controversial\r\n",
        "## due to reasons of simplicity and without being politically, we have decided to exclude the Kosovo from our analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaxkFISlKU6I"
      },
      "source": [
        "# ad 2) missing values in population\r\n",
        "# obtain countries with population total \r\n",
        "population_list_sorted = sorted(cleaned_income_data.loc[cleaned_income_data['population_total'].isna()].country_name.unique().tolist())\r\n",
        "print('\\nCountries with missing entries in their population values:')\r\n",
        "print('----------------------------------------------------------')\r\n",
        "print(*population_list_sorted, sep = '\\n')\r\n",
        "\r\n",
        "# strategy on dealing with missing in population values:\r\n",
        "\r\n",
        "## missing entries in population values can be traced back to former countries that no longer exist\r\n",
        "## because we know the former composition of that countries we can easily calculate their population values based on their components\r\n",
        "## at least this is a possible approach for large countries that have been splitted up: \r\n",
        "### Former Sudan, Former USSR, Former Yugoslavia, Yemen: Former Democratic Yemen, Yemen: Former Yemen Arab Republic\r\n",
        "### Former Czechoslovakia -> Czech Republic, Slovakia,\r\n",
        "### Former Ethiopia -> Ethiopia, Eritrea,\r\n",
        "### Former Sudan -> Sudan, South Sudan],\r\n",
        "### Former USSR -> Armenia, Azerbaijan, Belarus, Estonia, Georgia, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Republic of Moldova, Russian Federation, Tajikistan, Turkmenistan, Ukraine, Uzbekistan\r\n",
        "### Former Yugoslavia -> Bosnia and Herzegovina, Croatia, Montenegro, Republic of North Macedonia, Serbia, Slovenia\r\n",
        "\r\n",
        "## in case of Yemen we have a merge of two former countries for which the above mentioned approach is not possible\r\n",
        "## even if such a merge of two quite similiar countries (at least in gni_per_capita) is politically important, for our purposes it is not\r\n",
        "## therefore we decided to consider Yemen in our data as one country for the entire observation period\r\n",
        "\r\n",
        "## Kosovo has declared its independence from Serbia in 2008 but until today this declaration is quite controversial\r\n",
        "## due to reasons of simplicity and without being politically, we have decided to exclude the Kosovo from our analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD71IbE_PGoq"
      },
      "source": [
        "# ad 3) missing values in gni per capita\r\n",
        "# obtain countries with gni per capita\r\n",
        "gni_null_values = cleaned_income_data.gni_per_capita_us_dollar.isnull().groupby(cleaned_income_data['country_name']).sum().astype(int).reset_index(name = 'null_count')\r\n",
        "print('\\nCountries with missing entries in their gni per capita values:')\r\n",
        "print('--------------------------------------------------------------')\r\n",
        "print(gni_null_values[gni_null_values['null_count'] > 0])\r\n",
        "\r\n",
        "# strategy on dealing with missing in gni per capita values:\r\n",
        "## when taking a closer look at the data, almost all of the missing values at gni per capita can be traced back to years for which a country does not exist\r\n",
        "## therefore such entries with missing values at gni per capita can be safely removed but for Yemen a special handling will be required: \r\n",
        "## due to the similarity of the Yemen: Former Democratic Yemen and Yemen: Former Yemen Arab Republic we decided to calculate the mean of the gni per capita\r\n",
        "## of both countries and use it to replace the historical missing values of Yemen, for our work the separation between that two former countries is neglible"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2DP9IQR0FX2"
      },
      "source": [
        "## Handling missing country codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9PNnKnP0EaC"
      },
      "source": [
        "def handle_missing_country_codes(input_data):\r\n",
        "\r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop entries of Kosovo\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Kosovo'].index, inplace = True)\r\n",
        "  output_data.reset_index(drop = True, inplace = True)\r\n",
        "\r\n",
        "  # load formerly used country codes from csv, set na_filter to false in order to fix the issue of Namibia's iso_alpha2_code\r\n",
        "  former_country_codes = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/iso3166_formerly_used_country_codes.csv', sep = ';', na_filter = False)\r\n",
        "\r\n",
        "  country_codes_list = ['iso_alpha3_code', 'iso_alpha2_code', 'm49_code']   \r\n",
        "\r\n",
        "  # insert missing values from former_country_codes\r\n",
        "  for row_index in range(0, len(output_data)):\r\n",
        "      \r\n",
        "    for country_code in country_codes_list:\r\n",
        "        \r\n",
        "      # check if country code value is missing\r\n",
        "      if pd.isnull(output_data.loc[row_index, country_code]):\r\n",
        "\r\n",
        "        # insert missing country code\r\n",
        "        output_data.loc[row_index, country_code] = former_country_codes.loc[former_country_codes[former_country_codes['country_name'] == output_data.loc[row_index, 'country_name']].index[0], country_code]\r\n",
        "  \r\n",
        "  return output_data\r\n",
        "    \r\n",
        "income_data_country_codes_complete = handle_missing_country_codes(cleaned_income_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs8IqtlbG9_1"
      },
      "source": [
        "## Compute missing population data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ELhXWUHCYm"
      },
      "source": [
        "def compute_missing_population_total(input_data):\r\n",
        "\r\n",
        "    output_data = input_data.copy()\r\n",
        "\r\n",
        "    former_country_lists = [['Former Czechoslovakia', 'Czech Republic', 'Slovakia'],\r\n",
        "                             ['Former Ethiopia', 'Ethiopia', 'Eritrea'],\r\n",
        "                             ['Former Sudan', 'Sudan', 'South Sudan'],\r\n",
        "                             ['Former USSR', 'Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', \r\n",
        "                              'Republic of Moldova', 'Russian Federation', 'Tajikistan', 'Turkmenistan', 'Ukraine', 'Uzbekistan'],\r\n",
        "                             ['Former Yugoslavia', 'Bosnia and Herzegovina', 'Croatia', 'Montenegro', 'Republic of North Macedonia', 'Serbia', 'Slovenia']]\r\n",
        "\r\n",
        "    for country_list in former_country_lists:\r\n",
        "\r\n",
        "      # get first list elem of list\r\n",
        "      former_country_name = country_list.pop(0)\r\n",
        "\r\n",
        "      # get list of calendar_years\r\n",
        "      calendar_year_list = output_data.loc[output_data['country_name'] == former_country_name].calendar_year.tolist()\r\n",
        "\r\n",
        "      for calendar_year in calendar_year_list:\r\n",
        "        \r\n",
        "        # get current index of former_country at particular calender_year\r\n",
        "        curr_former_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == former_country_name)].population_total.index.max()\r\n",
        "        \r\n",
        "        # initialize new_population_total\r\n",
        "        new_population_total = 0\r\n",
        "\r\n",
        "        for country_name in country_list:\r\n",
        "          \r\n",
        "          if pd.isnull(output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == country_name)].gni_per_capita_us_dollar).bool():\r\n",
        "            \r\n",
        "            # get current index of country at particular calender_year  \r\n",
        "            curr_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == country_name)].population_total.index.max()\r\n",
        "\r\n",
        "            # increment new_population_total by population_total of curr_country_index at particular calender_year \r\n",
        "            new_population_total += output_data.loc[curr_country_index, 'population_total']\r\n",
        "\r\n",
        "        # update population_total of former_country with new_population_total at particular calender_year \r\n",
        "        output_data.loc[curr_former_country_index, 'population_total'] = new_population_total if new_population_total > 0 else np.nan\r\n",
        "\r\n",
        "    return output_data\r\n",
        "    \r\n",
        "income_data_population_total_complete = compute_missing_population_total(income_data_country_codes_complete)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWLF76kOJ0vU"
      },
      "source": [
        "## Fix missing gni per capita values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnEMO_CUKHi_"
      },
      "source": [
        "def fix_missing_gni_per_capita_values(input_data):\r\n",
        "  \r\n",
        "  output_data = input_data.copy()\r\n",
        "  \r\n",
        "  # set index on calendar_year\r\n",
        "  output_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  # special handling for 'Yemen': \r\n",
        "  # compute mean of gni per capita from 'Yemen: Former Democratic Yemen' and 'Yemen: Former Yemen Arab Republic'\r\n",
        "  # and replace missing values of 'Yemen' with the computed mean\r\n",
        "  yemen_missing_gni_values = (output_data[output_data['country_name'] == 'Yemen: Former Democratic Yemen'].gni_per_capita_us_dollar + output_data[output_data['country_name'] == 'Yemen: Former Yemen Arab Republic'].gni_per_capita_us_dollar) / 2\r\n",
        "  yemen_missing_gni_values.dropna(inplace = True)\r\n",
        "  yemen_df = pd.DataFrame(output_data[output_data['country_name'] == 'Yemen'].gni_per_capita_us_dollar.fillna(yemen_missing_gni_values))\r\n",
        "  yemen_df['country_name'] = 'Yemen'\r\n",
        "  yemen_df.reset_index(inplace = True)\r\n",
        "  yemen_df.set_index(['calendar_year', 'country_name'], inplace = True)\r\n",
        "  \r\n",
        "  # fill missing values of 'Yemen' with above computed values\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "  output_data.set_index(['calendar_year', 'country_name'], inplace = True)\r\n",
        "  output_data.fillna(yemen_df, inplace = True)\r\n",
        "\r\n",
        "  # reset index\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "  \r\n",
        "  # drop 'Yemen: Former Democratic Yemen' and 'Yemen: Former Yemen Arab Republic' due to consolidation\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Yemen: Former Democratic Yemen'].index, inplace = True)\r\n",
        "  output_data.drop(output_data[output_data['country_name'] == 'Yemen: Former Yemen Arab Republic'].index, inplace = True)\r\n",
        "  \r\n",
        "  # drop entries that still involve missing values is now safe \r\n",
        "  output_data.dropna(inplace = True)\r\n",
        "  output_data.reset_index(inplace = True, drop = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "income_data_preprocessed = fix_missing_gni_per_capita_values(income_data_population_total_complete)\r\n",
        "\r\n",
        "# check whether or not all missing values have been replaced\r\n",
        "sb.heatmap(income_data_preprocessed.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WucPBil7xQ8"
      },
      "source": [
        "## Load thresholds and sdr deflators\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALYXSRiPrnGY"
      },
      "source": [
        "def load_thresholds_sdr_deflators():\r\n",
        "  \r\n",
        "  # load income-level thresholds\r\n",
        "  income_threshold_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/world_bank_income_level_thresholds.csv', sep = ',')\r\n",
        "  income_threshold_data.drop(['banks_fiscal_year'], axis = 1, inplace = True)\r\n",
        "\r\n",
        "  # load sdr deflator values\r\n",
        "  sdr_deflator_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/world_bank_sdr_deflator.csv', sep = ',')\r\n",
        "  sdr_deflator_data.drop(['sdr_deflator_us_dollar'], axis = 1, inplace = True)\r\n",
        "\r\n",
        "  # create index on calendar_year\r\n",
        "  income_threshold_data.set_index(['calendar_year'], inplace = True)\r\n",
        "  sdr_deflator_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  # merge income_threshold_data and sdr_deflator_data using index 'calendar_year'\r\n",
        "  output_data = income_threshold_data.merge(sdr_deflator_data, how = 'inner', left_index = True, right_index = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "threshold_data = load_thresholds_sdr_deflators()\r\n",
        "\r\n",
        "# visualize missing threshold values using a heatmap\r\n",
        "sb.heatmap(threshold_data[['low_income_level_threshold', 'middle_income_level_threshold', 'high_income_level_threshold']].isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOA-6HmO8Dbp"
      },
      "source": [
        "## Calculate missing thresholds using sdr deflators\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UprCduwpmDL9"
      },
      "source": [
        "def calculate_missing_thresholds(input_data):\r\n",
        "    \r\n",
        "    output_data = input_data.copy()\r\n",
        "    \r\n",
        "    thresholds_list = ['low_income_level_threshold', 'middle_income_level_threshold', 'high_income_level_threshold']   \r\n",
        "    \r\n",
        "    # calculate missing values\r\n",
        "    for row_index in range(0, len(output_data)):\r\n",
        "      \r\n",
        "      # retrieve current index\r\n",
        "      curr_index = output_data.index.max() - row_index\r\n",
        "      for threshold in thresholds_list:\r\n",
        "        \r\n",
        "        # check if threshold value is missing\r\n",
        "        if(np.isnan(output_data.loc[curr_index, threshold])):\r\n",
        "          \r\n",
        "          # calculate missing threshold value based on existing threshold and sdr_inflation_rate_annual_change\r\n",
        "          output_data.loc[curr_index, threshold] = output_data.loc[curr_index + 1, threshold] / (100 + output_data.loc[curr_index + 1, 'sdr_inflation_rate_annual_change']) * 100\r\n",
        "    \r\n",
        "    # round thresholds to nearest multiple of base\r\n",
        "    base = 5\r\n",
        "    for threshold in thresholds_list:\r\n",
        "      output_data[threshold] = round(output_data[threshold] / base) * base\r\n",
        "\r\n",
        "    return output_data[thresholds_list]\r\n",
        "\r\n",
        "threshold_data_preprocessed = calculate_missing_thresholds(threshold_data)\r\n",
        "\r\n",
        "# check whether or not all missing values have been replaced\r\n",
        "sb.heatmap(threshold_data_preprocessed.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkwUcixAG-QB"
      },
      "source": [
        "## Assign income-level labels based on gni and income-level thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KFdBCwxyjEn"
      },
      "source": [
        "def assign_income_level_labels(input_income_data, input_threshold_data):\r\n",
        "\r\n",
        "  # merge income_data_preprocessed and threshold_data_complete using calendar_year\r\n",
        "  output_data = input_income_data.merge(input_threshold_data, how = 'left', on = 'calendar_year')\r\n",
        "\r\n",
        "  # assign income-level labels based on gni and thresholds\r\n",
        "  output_data.loc[(output_data['gni_per_capita_us_dollar'] <= output_data['low_income_level_threshold']), 'income_level_label'] = 'low_income'\r\n",
        "  output_data.loc[((output_data['gni_per_capita_us_dollar'] > output_data['low_income_level_threshold']) & \r\n",
        "                          (output_data['gni_per_capita_us_dollar'] <= output_data['middle_income_level_threshold'])), 'income_level_label'] = 'lower_middle_income'\r\n",
        "  output_data.loc[((output_data['gni_per_capita_us_dollar'] > output_data['middle_income_level_threshold']) & \r\n",
        "                          (output_data['gni_per_capita_us_dollar'] <= output_data['high_income_level_threshold'])), 'income_level_label'] = 'upper_middle_income'\r\n",
        "  output_data.loc[(output_data['gni_per_capita_us_dollar'] > output_data['high_income_level_threshold']), 'income_level_label'] = 'high_income'\r\n",
        "\r\n",
        "  # create index on calendar_year\r\n",
        "  output_data.set_index(['calendar_year'], inplace = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "income_classification_data = assign_income_level_labels(income_data_preprocessed, threshold_data_preprocessed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bLAKKKQrfsG"
      },
      "source": [
        "# Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEgcKVdKUEIA"
      },
      "source": [
        "## Calculating the population living in the different income levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w6atxv7UPYA"
      },
      "source": [
        "def calculate_sum_population_per_income_level_and_year(input_data):\r\n",
        "\r\n",
        "  output_data = pd.DataFrame()\r\n",
        "\r\n",
        "  # create sum of population of each income category for each year\r\n",
        "  output_data['low_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'low_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['lower_middle_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'lower_middle_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['upper_middle_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'upper_middle_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['high_income_population'] = input_data['population_total'].loc[input_data['income_level_label'] == 'high_income'].groupby('calendar_year').sum()\r\n",
        "  output_data['total_population'] = input_data['population_total'].groupby('calendar_year').sum()\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "population_income = calculate_sum_population_per_income_level_and_year(income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pAZB1E2vv_P"
      },
      "source": [
        "## Visualization of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYknZxtoajh_"
      },
      "source": [
        "# plot cumulative total population according to income-levels\r\n",
        "\r\n",
        "# select years to include in plot\r\n",
        "years = range(min(population_income.index), max(population_income.index))\r\n",
        "\r\n",
        "# calculate cumulative total_population according to income-levels\r\n",
        "low_income_cumulative = population_income.loc[population_income.index.isin(years), 'low_income_population'].values\r\n",
        "lower_middle_income_cumulative = low_income_cumulative + population_income.loc[population_income.index.isin(years), 'lower_middle_income_population'].values\r\n",
        "upper_middle_income_cumulative = lower_middle_income_cumulative + population_income.loc[population_income.index.isin(years), 'upper_middle_income_population'].values\r\n",
        "high_income_cumulative = upper_middle_income_cumulative + population_income.loc[population_income.index.isin(years), 'high_income_population'].values\r\n",
        "\r\n",
        "# create plot\r\n",
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "ax.plot(population_income['total_population'].groupby('calendar_year').max(), label = 'total_population', color = 'Black')\r\n",
        "ax.plot(population_income['total_population'].groupby('calendar_year').max() * 0.5, label = 'half_of_total_population', color = 'Red', linestyle = 'dashed')\r\n",
        "\r\n",
        "ax.fill_between(years ,upper_middle_income_cumulative, high_income_cumulative, alpha = 0.3, color = 'dodgerblue')\r\n",
        "ax.fill_between(years ,lower_middle_income_cumulative, upper_middle_income_cumulative, alpha= 0.3, color = 'skyblue')\r\n",
        "ax.fill_between(years, low_income_cumulative, lower_middle_income_cumulative, alpha = 0.3, color = 'lightcoral')\r\n",
        "ax.fill_between(years, low_income_cumulative, 0, alpha = 0.3, color = 'maroon')\r\n",
        "ax.text(1990, 1.5e9, 'low income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(1995, 3.5e9, 'lower_middle_income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(2003, 5e9, 'upper_middle_income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(2009, 6.5e9, 'high_income', fontsize = 9, color = 'Black')\r\n",
        "\r\n",
        "ax.set_title('Visualizing historical development of world\\'s population according to different \\n income-levels based on the information of more than 160 countries', pad = 20)\r\n",
        "ax.set_xlabel('Calendar Year')\r\n",
        "ax.set_ylabel('World\\'s Population')\r\n",
        "\r\n",
        "plt.xlim([min(population_income.index), max(population_income.index) - 1])\r\n",
        "plt.ylim([0, population_income['total_population'].max()])\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU6pGS17xehv"
      },
      "source": [
        "# show pie-plot of differtent income levels in the last available year (=2018)\r\n",
        "\r\n",
        "fig, ax = plt.subplots()\r\n",
        "population_income.loc[max(population_income.index),['low_income_population','lower_middle_income_population','upper_middle_income_population','high_income_population']].plot.pie(autopct='%.1f', pctdistance = 0.7, labels = ['low income', 'lower middle income', 'upper middle income', 'high income'], colors = ['maroon','lightcoral','skyblue','dodgerblue'])\r\n",
        "ax.set_title('Distribution of World\\'s Population according to different income-levels in 2018', pad = 20)\r\n",
        "plt.ylabel('')\r\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u55r7_GksFzB"
      },
      "source": [
        "# plot income of the 5 most populous countries in the last available year(= 2018)\r\n",
        "\r\n",
        "# select years to include in plot\r\n",
        "years = range(min(population_income.index), max(population_income.index))\r\n",
        "\r\n",
        "# select 5 largest countries\r\n",
        "countries_most_populous = income_classification_data.loc[max(population_income.index)].nlargest(5,'population_total')['country_name'].values\r\n",
        "\r\n",
        "# extract income thresholds\r\n",
        "high_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['high_income_level_threshold'].values\r\n",
        "middle_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['middle_income_level_threshold'].values\r\n",
        "low_income_treshold = threshold_data_preprocessed[threshold_data_preprocessed.index.isin(years)]['low_income_level_threshold'].values\r\n",
        "\r\n",
        "# create plot\r\n",
        "fig, ax = plt.subplots()\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  ax.plot(income_classification_data['gni_per_capita_us_dollar'].loc[income_classification_data['country_name'] == countries_most_populous[i]],label = countries_most_populous[i])\r\n",
        "\r\n",
        "#plot on logarithmic scale\r\n",
        "plt.yscale('log')\r\n",
        "\r\n",
        "#visualise thresholds and the different income classes\r\n",
        "ax.fill_between(years,high_income_treshold, 1e5,alpha = 0.3,color = 'dodgerblue')\r\n",
        "ax.fill_between(years,high_income_treshold, middle_income_treshold, alpha = 0.3,color = 'skyblue')\r\n",
        "ax.fill_between(years,low_income_treshold, middle_income_treshold, alpha = 0.3, color = 'lightcoral')\r\n",
        "ax.fill_between(years,low_income_treshold, 0, alpha = 0.3, color = 'maroon')\r\n",
        "ax.text(2004, 1.5e2, 'low income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(1980, 1.3e3, 'lower_middle_income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(1990, 5e3, 'upper_middle_income', fontsize = 9, color = 'Black')\r\n",
        "ax.text(2000, 2e4, 'high_income', fontsize = 9, color = 'Black')\r\n",
        "\r\n",
        "ax.set_title('GNI per Capita over Time for the 5 most populous Countries', pad = 20)\r\n",
        "ax.set_xlabel('Calendar Year')\r\n",
        "ax.set_ylabel('log(GNI per Capita in US Dollar)')\r\n",
        "\r\n",
        "plt.xlim([min(population_income.index), max(population_income.index) - 1])\r\n",
        "plt.ylim([5e1,1e5])\r\n",
        "plt.legend(loc='upper left',fontsize = 8)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_G9LRDcy3ml"
      },
      "source": [
        "# create df to show the sum of coutries for each income classification\r\n",
        "income_classification_count = income_classification_data['income_level_label'].groupby('calendar_year').value_counts(dropna = False)\r\n",
        "\r\n",
        "# plot total count of classification entries each year [sum of countries]\r\n",
        "fig, ax = plt.subplots()\r\n",
        "income_classification_total_count = income_classification_count[:,'high_income']+income_classification_count[:,'upper_middle_income']+income_classification_count[:,'lower_middle_income']+income_classification_count[:,'low_income']\r\n",
        "plt.plot(income_classification_total_count, label = 'total_classification_count', color = 'black')\r\n",
        "ax.set_title('Number of Classified Countries per Year', pad = 20)\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of Countries')\r\n",
        "plt.xlim([min(income_classification_total_count.index), max(income_classification_total_count.index) - 1])\r\n",
        "plt.ylim([0, 200])\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbIbmagseQai"
      },
      "source": [
        "# wollt ihr die beiden plots drinnen lassen, glaub die sind recht schwer zu interpretieren? Ich wÃ¼rde es auch mal rauswerfen\r\n",
        "# plot income classification count over time\r\n",
        "plt.plot(population_income['high_income_population'], label = 'high_income' )\r\n",
        "plt.plot(population_income['upper_middle_income_population'], label = 'upper_middle_income')\r\n",
        "plt.plot(population_income['lower_middle_income_population'], label = 'lower_middle_income')\r\n",
        "plt.plot(population_income['low_income_population'], label = 'low_income')\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of People')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# income_classification_data =  income_classification_data.loc[income_classification_data['population_total'] > 1000000.0]\r\n",
        "# print(income_classification_data)\r\n",
        "# print(income_classification_data[['population_total', 'income_level_label']].groupby(['calendar_year', 'income_level_label']).sum().groupby('calendar_year').sum())\r\n",
        "\r\n",
        "# plot income classification count over time [sum of countries]\r\n",
        "plt.plot(income_classification_count[:,'high_income'], label = 'high_income' )\r\n",
        "plt.plot(income_classification_count[:,'upper_middle_income'], label = 'upper_middle_income')\r\n",
        "plt.plot(income_classification_count[:,'lower_middle_income'], label = 'lower_middle_income')\r\n",
        "plt.plot(income_classification_count[:,'low_income'], label = 'low_income')\r\n",
        "plt.xlabel('Calendar Year')\r\n",
        "plt.ylabel('Number of Countries')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yghsEQkMNPlr"
      },
      "source": [
        "## Interactive world map (choropleth map)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrh3_7tl9pMV"
      },
      "source": [
        "def preprocessing_world_map_data(input_data):\r\n",
        "\r\n",
        "  output_data = input_data.copy()\r\n",
        "\r\n",
        "  # drop index on calendar_year\r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "\r\n",
        "  former_country_lists = [['Former Czechoslovakia', 'Czech Republic', 'Slovakia'],\r\n",
        "                             ['Former Ethiopia', 'Ethiopia', 'Eritrea'],\r\n",
        "                             ['Former Sudan', 'Sudan', 'South Sudan'],\r\n",
        "                             ['Former USSR', 'Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', \r\n",
        "                              'Republic of Moldova', 'Russian Federation', 'Tajikistan', 'Turkmenistan', 'Ukraine', 'Uzbekistan'],\r\n",
        "                             ['Former Yugoslavia', 'Bosnia and Herzegovina', 'Croatia', 'Montenegro', 'Republic of North Macedonia', 'Serbia', 'Slovenia']]\r\n",
        "\r\n",
        "  for country_list in former_country_lists:\r\n",
        "\r\n",
        "    # get first list elem of list\r\n",
        "    former_country_name = country_list.pop(0)\r\n",
        "\r\n",
        "    # get list of calendar_years\r\n",
        "    calendar_year_list = output_data.loc[output_data['country_name'] == former_country_name].calendar_year.tolist()\r\n",
        "    \r\n",
        "    for calendar_year in calendar_year_list:\r\n",
        "\r\n",
        "      # get current index of former country at particular calender_year  \r\n",
        "      curr_former_country_index = output_data.loc[(output_data['calendar_year'] == calendar_year) & (output_data['country_name'] == former_country_name)].income_level_label.index.max()\r\n",
        "\r\n",
        "      # get income-level of former country\r\n",
        "      income_level_label = output_data.loc[curr_former_country_index, 'income_level_label']\r\n",
        "      \r\n",
        "      # get max calender year of dataframe\r\n",
        "      max_calendar_year = max(output_data['calendar_year'])\r\n",
        "\r\n",
        "      for country_name in country_list:\r\n",
        "        \r\n",
        "        # get current index of country at particular calender_year  \r\n",
        "        curr_country_index = output_data.loc[(output_data['calendar_year'] ==  max_calendar_year) & (output_data['country_name'] == country_name)].income_level_label.index.max()\r\n",
        "\r\n",
        "        # get income-level of former country\r\n",
        "        iso_alpha3_code = output_data.loc[curr_country_index, 'iso_alpha3_code']\r\n",
        "\r\n",
        "        # append row to dataframe\r\n",
        "        output_data = output_data.append({'calendar_year' : calendar_year, \r\n",
        "                                          'iso_alpha3_code' : iso_alpha3_code,\r\n",
        "                                          'country_name' :  country_name, \r\n",
        "                                          'income_level_label' : income_level_label} , ignore_index = True)\r\n",
        "\r\n",
        "  # set index on calendar_year\r\n",
        "  output_data.reset_index(inplace = True, drop = True)\r\n",
        "  output_data.sort_values(by = ['country_name', 'calendar_year'], inplace = True)\r\n",
        "  output_data.set_index('calendar_year', inplace = True)\r\n",
        "\r\n",
        "  return output_data\r\n",
        "\r\n",
        "world_map_data = preprocessing_world_map_data(income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZeHmghtNOl7"
      },
      "source": [
        "@interact(selected_year = IntSlider(value = min(world_map_data.index), min = min(world_map_data.index), max = max(world_map_data.index)))\r\n",
        "def interactive_world_map_visualization_(selected_year):\r\n",
        "  \r\n",
        "  # load geometry data for all countries \r\n",
        "  world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\r\n",
        "\r\n",
        "  # correct wrong iso code\r\n",
        "  world.loc[world['name'] == 'France', 'iso_a3'] = 'FRA'\r\n",
        "  world.loc[world['name'] == 'Norway', 'iso_a3'] = 'NOR'\r\n",
        "  world.loc[world['name'] == 'Kosovo', 'iso_a3'] = 'XKX'\r\n",
        "\r\n",
        "  # drop unnecessary columns\r\n",
        "  country_shapes = world[['geometry', 'iso_a3']]\r\n",
        "\r\n",
        "  # merge geometry with income data on country code, select year to look at\r\n",
        "  geo_income_data = country_shapes.merge(world_map_data.loc[selected_year], left_on='iso_a3', right_on='iso_alpha3_code')\r\n",
        "\r\n",
        "  # plot map\r\n",
        "  legend_dict = {'bbox_to_anchor' : (1., 1), 'loc' :'upper left'}\r\n",
        "  colors = ['dodgerblue','maroon','lightcoral','skyblue']\r\n",
        "  geo_income_data.plot(column='income_level_label', legend = True, legend_kwds = legend_dict, figsize=(15, 10), cmap = matplotlib.colors.ListedColormap(colors) )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maNKqI1AYRo0"
      },
      "source": [
        "# Data Preprocessing of Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99raLyMor7k"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7KcaJodYlwS"
      },
      "source": [
        "def load_world_bank_indicator_data():\r\n",
        "  # load indicator data from csv (World Bank Data) (https://databank.worldbank.org/source/world-development-indicators/)\r\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/data_indicators_2.csv', sep = ',', nrows = 16104)\r\n",
        "  data.replace('..',np.nan,inplace=True)\r\n",
        "\r\n",
        "  #rename columns\r\n",
        "  rename_columns_dict = {'Time':'calendar_year','Country Code':'iso_alpha3_code','Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]':'fertility_rate','Urban population (% of total population) [SP.URB.TOTL.IN.ZS]':'urban_population','Access to electricity (% of population) [EG.ELC.ACCS.ZS]':'access_electricity', 'Agriculture, forestry, and fishing, value added (% of GDP) [NV.AGR.TOTL.ZS]':'agriculture_forestry_fishing_sector','Unemployment, total (% of total labor force) (modeled ILO estimate) [SL.UEM.TOTL.ZS]':'unemployment', 'Total natural resources rents (% of GDP) [NY.GDP.TOTL.RT.ZS]':'natural_resources_rent','Inflation, consumer prices (annual %) [FP.CPI.TOTL.ZG]':'inflation','External balance on goods and services (% of GDP) [NE.RSB.GNFS.ZS]':'external_balance_on_goods_and_services','School enrollment, primary (% gross) [SE.PRM.ENRR]':'primary_school_enrollment','Life expectancy at birth, total (years) [SP.DYN.LE00.IN]':'life_expectancy'}\r\n",
        "  data.rename(rename_columns_dict, axis='columns',inplace=True)\r\n",
        "\r\n",
        "  #only use Data from 1995-2018. Some indicators are not available before 1995\r\n",
        "  data = data[data['calendar_year'].isin(range(1995,2019))]\r\n",
        "\r\n",
        "  # select only ceratain parameters (drop columns with very few entries)\r\n",
        "  data = data[['calendar_year','iso_alpha3_code','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy']]\r\n",
        "\r\n",
        "  #change data types of columns\r\n",
        "  data = data.astype({'fertility_rate': float, 'urban_population': float, 'access_electricity': float, 'agriculture_forestry_fishing_sector': float, 'inflation': float, 'external_balance_on_goods_and_services': float, 'natural_resources_rent': float, 'life_expectancy': float})\r\n",
        "\r\n",
        "  return data\r\n",
        "\r\n",
        "indicator_data = load_world_bank_indicator_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFicsejjOb5N"
      },
      "source": [
        "def load_corruption_perceptions_index():\r\n",
        "  #load corruption_perceptions_index provided by Transperancy International (https://www.transparency.org/en/cpi/2019/results)\r\n",
        "  data = pd.read_excel('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/CPI2019.xlsx', sheet_name= 'CPI Timeseries 2012 - 2019',header = 2, usecols = ['ISO3', 'CPI score 2018','CPI score 2017','CPI score 2016','CPI score 2015','CPI score 2014','CPI Score 2013','CPI Score 2012' ] )\r\n",
        "  data.rename({'ISO3': 'iso_alpha3_code', 'CPI score 2018':2018,'CPI score 2017':2017,'CPI score 2016':2016,'CPI score 2015':2015,'CPI score 2014':2014,'CPI Score 2013':2013,'CPI Score 2012':2012}, axis='columns',inplace =True)\r\n",
        "  \r\n",
        "  #transform dataframe\r\n",
        "  cpi_data_complete = pd.melt(data, id_vars=['iso_alpha3_code'], value_vars=range(2012,2019),var_name = 'calendar_year', value_name = 'corruption_perceptions_index')\r\n",
        "\r\n",
        "  #load data from 1995 - 2011\r\n",
        "  for i in range(1995, 2011+1):\r\n",
        "    year_data = pd.read_csv('/content/drive/MyDrive/Git/dopp_2020w_group03_ex3/data/CPI-' + str(i) +'.csv', sep = ',', usecols = ['iso','score'])\r\n",
        "    year_data['calendar_year'] = i\r\n",
        "    year_data.rename({'iso': 'iso_alpha3_code', 'score':'corruption_perceptions_index'},axis='columns',inplace =True)\r\n",
        "\r\n",
        "    year_data = year_data.astype({'corruption_perceptions_index': float})\r\n",
        "\r\n",
        "    #multiply corruption_perceptions_index with factor 10 for calendar years 1995 - 2011. Score was then between 0 and 10. From 2012-2018 score is between 0 and 100. Therfore the score is scaled up to match the data from 2012 to 2018\r\n",
        "    year_data['corruption_perceptions_index'] = year_data['corruption_perceptions_index'] *10\r\n",
        "\r\n",
        "    #add year i to cpi dataframe\r\n",
        "    cpi_data_complete = pd.concat([cpi_data_complete, year_data],ignore_index=True)\r\n",
        "\r\n",
        "  cpi_data_complete = cpi_data_complete.astype({'corruption_perceptions_index': float})\r\n",
        "  return cpi_data_complete\r\n",
        "\r\n",
        "cpi_data = load_corruption_perceptions_index()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGjAsIo9o0hm"
      },
      "source": [
        "## Merge with Data from Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxHHmiKfomPz"
      },
      "source": [
        "def merge_indicator_and_income_data(indicator, cpi,income):\r\n",
        "  merged_indicator_income_data = income.merge(indicator, how = 'inner', on = ['calendar_year','iso_alpha3_code'])\r\n",
        "  merged_data_complete = merged_indicator_income_data.merge(cpi, how = 'left', on = ['calendar_year','iso_alpha3_code'])\r\n",
        "\r\n",
        "  #set index \r\n",
        "  merged_data_complete.set_index(['calendar_year','country_name'], inplace = True)\r\n",
        "\r\n",
        "  return merged_data_complete\r\n",
        "\r\n",
        "indicator_income_data = merge_indicator_and_income_data(indicator_data,cpi_data, income_classification_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhqE30CwwyJa"
      },
      "source": [
        "## Deal with missing data and outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd0_tKnjw5M2"
      },
      "source": [
        "sb.heatmap(indicator_income_data.isna(), cbar = False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DutppAFdHLF"
      },
      "source": [
        "def clean_data(input_data):\r\n",
        "  output_data= input_data.copy()\r\n",
        "\r\n",
        "  #Remove all countries with missing indicator entries (exception: corruption_perceptions_index) \r\n",
        "  # The corruption_perceptions_index exists since 1995, but only for few countries. \r\n",
        "  output_data.dropna(subset = ['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy'], inplace = True)\r\n",
        "\r\n",
        "  #store the index of the droped rows for further analysis of the missing data\r\n",
        "  droped_rows = input_data[~input_data.index.isin(output_data.index)].index.to_frame(index=False)\r\n",
        "  droped_rows.set_index('calendar_year', inplace = True)\r\n",
        "  \r\n",
        "  \r\n",
        "  return output_data, droped_rows\r\n",
        "\r\n",
        "indicator_income_data_cleaned, droped_rows_cleaning = clean_data(indicator_income_data)\r\n",
        "\r\n",
        "indicator_income_data_cleaned\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_K1OuLhiEpO"
      },
      "source": [
        "droped_rows_cleaning.value_counts().hist(bins = 29)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "display(droped_rows_cleaning.value_counts())\r\n",
        "\r\n",
        "\r\n",
        "#in the droped_rows_cleaning dataframe it can be seen that some countries where completly deleted (All 24 years). \r\n",
        "#This is due to the fact that some indicators wheren't available for that countries. When you look at the droped rows in more detail it can be seen that they are mostly missing in many consecutive years. \r\n",
        "#Also the droped rows are always located on the \"edges\" of the available data([1995 - x] or [y - 2018]). Therfore the missing data only could be extrapolated and not interpolated. This would lead to highly unceratain predictions. \r\n",
        "#We choose not to guess the missing indicators to avoid making wrong predictions. In the Following ML- Algorithm we only use years where few rows where dropped.\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFQ7I5iaKq37"
      },
      "source": [
        "sb.heatmap(indicator_income_data_cleaned.isna(), cbar = False);\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buSNbsD_PrwE"
      },
      "source": [
        "## Deal with outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkM36SzjPuQm"
      },
      "source": [
        "# Discovering outliers with visualization tool Box plot\r\n",
        "\r\n",
        "def outliersBoxPlot (input_data):\r\n",
        "  \r\n",
        "  data = input_data.copy()\r\n",
        "  #Remove all countries with missing indicator values\r\n",
        "  data.dropna(subset = ['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy','corruption_perceptions_index'], inplace = True)\r\n",
        "\r\n",
        "  fig, axs = plt.subplots(3,4)\r\n",
        "  axs[0,0].boxplot(data['fertility_rate'])\r\n",
        "  axs[0,0].set_title('fertility_rate')\r\n",
        "  axs [0,1].boxplot(data['urban_population'])\r\n",
        "  axs [0,1].set_title('urban_population')\r\n",
        "  axs[0,2].boxplot(data['access_electricity'])\r\n",
        "  axs[0,2].set_title('access_electricity')\r\n",
        "  axs [0,3].boxplot(data['agriculture_forestry_fishing_sector'])\r\n",
        "  axs [0,3].set_title('agriculture_forestry_fishing_sector')\r\n",
        "  axs[1,0].boxplot(data['external_balance_on_goods_and_services'])\r\n",
        "  axs[1,0].set_title('external_balance_on_goods_and_services')\r\n",
        "  axs [1,1].boxplot(data['natural_resources_rent'])\r\n",
        "  axs [1,1].set_title('natural_resources_rent')\r\n",
        "  axs[1,2].boxplot(data['inflation'])\r\n",
        "  axs[1,2].set_title('inflation')\r\n",
        "  axs [1,3].boxplot(data['life_expectancy'])\r\n",
        "  axs [1,3].set_title('life_expectancy1')\r\n",
        "  axs [2,0].boxplot(data['corruption_perceptions_index'])\r\n",
        "  axs [2,0].set_title('corruption_perceptions_index')\r\n",
        "\r\n",
        "  fig.subplots_adjust(left=0.05, right=0.98, bottom=0.05, top=1.5,\r\n",
        "                    hspace=1, wspace=1)\r\n",
        "\r\n",
        "outliersBoxPlot(indicator_income_data_cleaned)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1deWVmqAcv5"
      },
      "source": [
        "# Discovering outliers with mathematical function\n",
        "def outlierZScore(input_data):\n",
        "  \n",
        "  # Z-score\n",
        "  # With Z-score we re-scale and center the data and look for data points which are too far from zero. Data points which are too far from zero will be treated as outliers.\n",
        "  # In the most cases a threshold of 3 or -3 is used. Z-score values greater than or less than 3 or -3 respectively is an outlier.\n",
        "\n",
        "  # defining threshold\n",
        "  threshold = 3\n",
        "\n",
        "  # features which are considered to be used to train the ML algorithm\n",
        "  features = ['fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy','corruption_perceptions_index']\n",
        "  df = pd.DataFrame()\n",
        "  df = input_data.copy()\n",
        "  \n",
        "  #Remove all countries with missing indicator values\n",
        "  df.dropna(subset = features, inplace = True)\n",
        "  \n",
        "  # Function to compute z-score \n",
        "  z = np.abs(stats.zscore(df[features]))\n",
        "  #print(z)\n",
        "  #print()\n",
        "\n",
        "  # The first array contains the list of row numbers and the second array respective column numbers\n",
        "  outliers = np.where(z > 3)\n",
        "  #print(outliers)\n",
        "\n",
        "  out_rows = outliers[0]\n",
        "  out_columns = outliers[1]\n",
        "  #print(len(out_rows))\n",
        "  #print(len(out_columns))\n",
        "\n",
        "  display(df.iloc[48])\n",
        "  \n",
        "  output_data = [] \n",
        "\n",
        "  for x in range(len(out_rows)):\n",
        "    row = pd.DataFrame()\n",
        "    row = df.iloc[out_rows[x]].copy()\n",
        "    row['outlier'] = features[out_columns[x]]\n",
        "    output_data.append(row)\n",
        "    \n",
        "  outDataFrame = pd.DataFrame(output_data)\n",
        "  cols = list(outDataFrame.columns.values)\n",
        "  cols = cols[-1:] + cols[:-1]\n",
        "  #display(cols)\n",
        "  outDataFrame = outDataFrame[cols]\n",
        "  pd.set_option('display.max_rows', 500)\n",
        "  display(outDataFrame)\n",
        "\n",
        "\n",
        "outlierZScore(indicator_income_data_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyjNGIGEFgrA"
      },
      "source": [
        "# exploring outliers\n",
        "def exploreOutlier(country_name, feature):\n",
        "  \n",
        "  country = indicator_income_data_cleaned.iloc[indicator_income_data_cleaned.index.get_level_values('country_name') == country_name]\n",
        "  print(country[feature])\n",
        "\n",
        "exploreOutlier('Nigeria','inflation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUQw2JJBeRb8"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbihL2eKwedV"
      },
      "source": [
        "sb.heatmap(indicator_income_data_cleaned.isna(), cbar = False);\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aANwuQjg3apf"
      },
      "source": [
        "sb.countplot(indicator_income_data_cleaned['income_level_label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0qh4WJyUsX-"
      },
      "source": [
        "def plot_scatter_matrix(input_data):\r\n",
        "  # Scatterplot Matrix\r\n",
        "  sm = pd.plotting.scatter_matrix(input_data[['income_level_label','gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy','corruption_perceptions_index']], figsize=(18, 18), diagonal='hist')\r\n",
        "  #Change label rotation\r\n",
        "  [s.xaxis.label.set_rotation(90) for s in sm.reshape(-1)]\r\n",
        "  [s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]\r\n",
        "  #May need to offset label when rotating to prevent overlap of figure\r\n",
        "  [s.get_yaxis().set_label_coords(-0.6,0.5) for s in sm.reshape(-1)]\r\n",
        "  #Hide all ticks\r\n",
        "  [s.set_xticks(()) for s in sm.reshape(-1)]\r\n",
        "  [s.set_yticks(()) for s in sm.reshape(-1)]\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "plot_scatter_matrix(indicator_income_data_cleaned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYpGEobg8FYw"
      },
      "source": [
        "def plot_gni_scatter_plot(input_data):\r\n",
        "\r\n",
        "  #plot scatter plot with colorized classification and logarithmic scale for gni per capita\r\n",
        "\r\n",
        "  #create income level number\r\n",
        "  # low_income = 1\r\n",
        "  # lower_middle_income = 2\r\n",
        "  # upper_middle_income = 3\r\n",
        "  # high_income = 4\r\n",
        "  scatter_data = input_data.copy()\r\n",
        "  scatter_data['income_classification_number'] = np.nan\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'low_income', 'income_classification_number'] = 1\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'lower_middle_income',['income_classification_number']] = 2\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'upper_middle_income',['income_classification_number']] = 3\r\n",
        "  scatter_data.loc[scatter_data['income_level_label'] == 'high_income',['income_classification_number']] = 4\r\n",
        "\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['fertility_rate'], scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c = scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('fertility_rate')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['urban_population'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('urban_population')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['access_electricity'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('access_electricity')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['agriculture_forestry_fishing_sector'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('agriculture_forestry_fishing_sector')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['inflation'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('inflation')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['external_balance_on_goods_and_services'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'].values,s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('external_balance_on_goods_and_services')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['natural_resources_rent'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('natural_resources_rent')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['life_expectancy'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('life_expectancy')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  fig = plt.figure()\r\n",
        "  ax = plt.gca()\r\n",
        "  plt.scatter(scatter_data['corruption_perceptions_index'],scatter_data['gni_per_capita_us_dollar'],\\\r\n",
        "              c=scatter_data['income_classification_number'],s = 1)\r\n",
        "  ax.set_yscale('log')\r\n",
        "  ax.set_xlabel('corruption_perceptions_index')\r\n",
        "  ax.set_ylabel('GNI per Capita in US Dollar')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "plot_gni_scatter_plot(indicator_income_data_cleaned)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnO2os3HuLOw"
      },
      "source": [
        "def plot_correlation_matrix(correlation_matrix_data):\r\n",
        "  # Full correlation matrix\r\n",
        "\r\n",
        "  colum_names = ['gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy','corruption_perceptions_index']\r\n",
        "  # Correlation matrix\r\n",
        "  correlations = correlation_matrix_data[['gni_per_capita_us_dollar','fertility_rate','urban_population','access_electricity', 'agriculture_forestry_fishing_sector','external_balance_on_goods_and_services','natural_resources_rent','inflation','life_expectancy', 'corruption_perceptions_index']].corr()\r\n",
        "  # Plot figsize\r\n",
        "  fig, ax = plt.subplots(figsize=(12, 12))\r\n",
        "  # Generate Color Map\r\n",
        "  colormap = sb.diverging_palette(220, 10, as_cmap=True)\r\n",
        "  # Generate Heat Map, allow annotations and place floats in map\r\n",
        "  sb.heatmap(correlations, cmap=colormap, annot=True, fmt=\".2f\")\r\n",
        "  ax.set_xticklabels(\r\n",
        "      colum_names,\r\n",
        "      rotation=45,\r\n",
        "      horizontalalignment='right'\r\n",
        "  );\r\n",
        "  ax.set_yticklabels(colum_names);\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  display(correlations)\r\n",
        "\r\n",
        "plot_correlation_matrix(indicator_income_data_cleaned)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ7WDLvKrhFR"
      },
      "source": [
        "# ML Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdlWDpYVzgQf"
      },
      "source": [
        "## Separate train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW9sfvdAxqnv"
      },
      "source": [
        "def separate_training_test_data(input_series, rnd):\r\n",
        "\r\n",
        "  # retrieve number of columns of input_data\r\n",
        "  n_cols = len(input_series.columns)\r\n",
        "    \r\n",
        "  # split up input_series into X and y\r\n",
        "  X = input_series.reset_index().iloc[:, 1:n_cols].values\r\n",
        "  y = input_series.reset_index().iloc[:, n_cols:(n_cols+1)].values.reshape(-1)\r\n",
        "\r\n",
        "  # separate training and test data with test_size = 0.2\r\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2, random_state = rnd)\r\n",
        "  \r\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fZFZjVsnHH"
      },
      "source": [
        "## Build random forest classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZk2Qlzh0h2X"
      },
      "source": [
        "def build_random_forest_classifier(X, y, k, rnd):\r\n",
        "\r\n",
        "  # set up grid-search to optimize hyperparameters of random forest algorithm\r\n",
        "  ## n_estimators ... number of trees in random forest\r\n",
        "  ## max_depth ... maximum depth in trees\r\n",
        "  ## max_features ... number of considered features\r\n",
        "  ## min_samples_split ... minimum number of samples for node splitting\r\n",
        "  ## min_samples_leaf ... minimum number of samples for leaf node\r\n",
        "  ## bootstrap ... bootstrap samples used for building trees\r\n",
        "  gsc = GridSearchCV(\r\n",
        "      estimator = RandomForestClassifier(random_state = rnd),\r\n",
        "      param_grid = {\r\n",
        "          'n_estimators': [50, 100, 150],\r\n",
        "          'max_depth': [2, 4, 8],\r\n",
        "          'max_features' : ['auto', 'sqrt', 'log2'],\r\n",
        "          'min_samples_split': [2, 3, 5],\r\n",
        "          'min_samples_leaf' : [1, 2, 5],\r\n",
        "          'bootstrap' : [True, False]\r\n",
        "      },\r\n",
        "      cv = k // 3, # divide k by 3 to reduce execution time\r\n",
        "      scoring = 'f1_weighted', \r\n",
        "      n_jobs = -1 # use all processors available\r\n",
        "  )\r\n",
        "  \r\n",
        "  # obtain hyperparameters through grid-search\r\n",
        "  gsc_result = gsc.fit(X, y)\r\n",
        "  best_params = gsc_result.best_params_\r\n",
        "\r\n",
        "  # build random forest clasification model\r\n",
        "  rfcl = RandomForestClassifier(\r\n",
        "      n_estimators = best_params['n_estimators'],  \r\n",
        "      max_depth = best_params['max_depth'],\r\n",
        "      max_features = best_params['max_features'],\r\n",
        "      min_samples_split = best_params['min_samples_split'],\r\n",
        "      min_samples_leaf = best_params['min_samples_leaf'],\r\n",
        "      bootstrap = best_params['bootstrap'],\r\n",
        "      random_state = rnd)\r\n",
        "  \r\n",
        "  # initialize cross-validation settings\r\n",
        "  cv = KFold(n_splits = k, random_state = rnd, shuffle = True)\r\n",
        "\r\n",
        "  # use k-fold cv for train-/validation-split when fitting the model\r\n",
        "  for train_index, val_index in cv.split(X):\r\n",
        "    \r\n",
        "    X_train, X_val = X[train_index], X[val_index]\r\n",
        "    y_train, y_val = y[train_index], y[val_index]\r\n",
        "    \r\n",
        "    # fit random forest classification model to data\r\n",
        "    rfcl.fit(X_train, y_train)\r\n",
        "\r\n",
        "  return rfcl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5ufkn3Y2iBS"
      },
      "source": [
        "## Perform classification of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38rdgV5_6S3A"
      },
      "source": [
        "def perform_label_classification(input_series, parameters, k, rnd):\r\n",
        "   \r\n",
        "   series = input_series.copy()\r\n",
        "\r\n",
        "   # drop remaining rows with nan-values      \r\n",
        "   series.dropna(inplace = True)\r\n",
        "\r\n",
        "   # separate train and test data\r\n",
        "   X_train, X_test, y_train, y_test = separate_training_test_data(series, rnd)\r\n",
        "\r\n",
        "   # build random forest classification model\r\n",
        "   rfcl = build_random_forest_classifier(X_train, y_train, k, rnd)\r\n",
        "      \r\n",
        "   # prediction based on features of test data\r\n",
        "   y_pred = rfcl.predict(X_test)\r\n",
        "\r\n",
        "   # retrieve labels of income-levels\r\n",
        "   labels = np.unique(y_test)\r\n",
        "\r\n",
        "   # compute weighted evaluation metrics\r\n",
        "   f1_wt = f1_score(y_test, y_pred, average = 'weighted', labels = labels, zero_division = 1)\r\n",
        "   precision_wt = precision_score(y_test, y_pred, average = 'weighted', labels = labels, zero_division = 1)\r\n",
        "   recall_wt = recall_score(y_test, y_pred, average = 'weighted', labels = labels, zero_division = 1)\r\n",
        "   \r\n",
        "   # compute precision for each income-level\r\n",
        "   precision_income_level = precision_score(y_test, y_pred, average = None, labels = labels)\r\n",
        "   \r\n",
        "   # store results of evaluation metrics in dictionaries\r\n",
        "   result_dict_wt = dict(zip(['f1', 'precision', 'recall'], [f1_wt, precision_wt, recall_wt]))\r\n",
        "   result_dict_income_level = dict(zip(labels, precision_income_level))\r\n",
        "\r\n",
        "   # create confusion matrix\r\n",
        "   confusion_mx = confusion_matrix(y_test, y_pred, labels = labels)\r\n",
        "   confusion_mx_data = pd.DataFrame(confusion_mx, index = labels, columns = labels)\r\n",
        "   \r\n",
        "   # obtain feature importance\r\n",
        "   feature_importance = pd.Series(rfcl.feature_importances_, index = parameters, \r\n",
        "                                  name = 'feature_importance').sort_values(ascending = False)\r\n",
        "\r\n",
        "   return result_dict_wt, result_dict_income_level, confusion_mx_data, feature_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZj3PqMIaAEu"
      },
      "source": [
        "## Selection of calendar year and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZQfiDMUYuaE"
      },
      "source": [
        "def selection_of_calendar_year(input_data, calendar_year, parameters):\r\n",
        "  \r\n",
        "  output_data = input_data.copy()\r\n",
        "  \r\n",
        "  output_data.reset_index(inplace = True)\r\n",
        "  output_data = output_data.loc[output_data['calendar_year'] == calendar_year]\r\n",
        "  output_data.set_index(['calendar_year', 'country_name'], inplace = True)\r\n",
        "  \r\n",
        "  return output_data[parameters]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP63AzOs4bcM"
      },
      "source": [
        "# Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xOcvAKpwSsJ"
      },
      "source": [
        "## Classification of income-level labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boj3eUee2qkU"
      },
      "source": [
        "def classify_income_level_labels(input_data, calendar_year, k, seed):\r\n",
        "\r\n",
        "  parameters = ['fertility_rate', 'urban_population', 'access_electricity', \r\n",
        "                    'agriculture_forestry_fishing_sector', \r\n",
        "                    'external_balance_on_goods_and_services', \r\n",
        "                    'life_expectancy', 'natural_resources_rent', \r\n",
        "                    'inflation', 'corruption_perceptions_index']\r\n",
        "  \r\n",
        "  label = ['income_level_label']\r\n",
        "\r\n",
        "  data = selection_of_calendar_year(input_data, calendar_year, parameters + label)\r\n",
        "\r\n",
        "  # initialize random seed in order to ensure reproducible results\r\n",
        "  np.random.seed(seed)\r\n",
        "  rnd = np.random.randint(0,1000)\r\n",
        "\r\n",
        "  # extract series of specific calendar_year   \r\n",
        "  series = data.loc[calendar_year]\r\n",
        "\r\n",
        "  # separate train and test data\r\n",
        "  X_train, X_test, y_train, y_test = separate_training_test_data(series, rnd)\r\n",
        "\r\n",
        "  # starttime \r\n",
        "  print('start: ', datetime.now().time())\r\n",
        "\r\n",
        "  # perform income-level classifications\r\n",
        "  result = perform_label_classification(series, parameters, k, rnd)\r\n",
        "\r\n",
        "  # endtime\r\n",
        "  print('end: ', datetime.now().time())\r\n",
        "\r\n",
        "  return result\r\n",
        "\r\n",
        "result_dict_wt, result_dict_income_level, confusion_mx_data, feature_importance = classify_income_level_labels(indicator_income_data_cleaned, 2018, 10, 56)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MfUc9NZ3Oc8"
      },
      "source": [
        "## Evaluation of metrics and visualization of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKsGA3JECdS6"
      },
      "source": [
        "print(result_dict_wt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PK32D8aCddr"
      },
      "source": [
        "print(result_dict_income_level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBlXDIHNCdmz"
      },
      "source": [
        "print(confusion_mx_data.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SftMpRssCdwh"
      },
      "source": [
        "print(feature_importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5wMWmgU4gSN"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwhTlK0G6eXS"
      },
      "source": [
        "## Compute a new column that shows whether or not a change in income-level occured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydtqOz099hPl"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACAMRoN2uJL6"
      },
      "source": [
        "def get_IndicatorLevelChange(inputdata, firstyear, secondyear):\n",
        "  data = inputdata.copy()\n",
        "  output = inputdata.copy()\n",
        "  data = get_incomeClassificationNumber(data)\n",
        "  data['level_change'] = np.nan\n",
        "  \n",
        "  data1 = data.loc[firstyear]\n",
        "  data2 = data.loc[secondyear]\n",
        "  \n",
        "  output = get_change(data1, data2)\n",
        "  \n",
        "  #data1 = data1.set_index(['calender_year','country_name'])\n",
        "  #display(data1)\n",
        "\n",
        "  return output\n",
        "\n",
        "change_dataset = get_IndicatorLevelChange(indicator_income_data_cleaned,2008,2018)\n",
        "display(change_dataset.loc[:,'level_change'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwAuED4zSh3"
      },
      "source": [
        "def get_incomeClassificationNumber (inputdata):\n",
        "  data = inputdata.copy()\n",
        "\n",
        "  data['income_classification_number'] = np.nan\n",
        "  data.loc[data['income_level_label'] == 'low_income', 'income_classification_number'] = 1\n",
        "  data.loc[data['income_level_label'] == 'lower_middle_income',['income_classification_number']] = 2\n",
        "  data.loc[data['income_level_label'] == 'upper_middle_income',['income_classification_number']] = 3\n",
        "  data.loc[data['income_level_label'] == 'high_income',['income_classification_number']] = 4\n",
        "  \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiMhYhRb1B5q"
      },
      "source": [
        "def get_change(data1, data2):\n",
        "  output = data1.copy()\n",
        "\n",
        "  for x in data1.index:\n",
        "    try: #try running the loop\n",
        "      level1 = data1.loc[x,'income_classification_number']\n",
        "      #print(level1)\n",
        "      level2 = data2.loc[x,'income_classification_number']\n",
        "      #print(level2)\n",
        "      if level1 > level2:\n",
        "        data1.loc[x, 'level_change'] = 'higher'        \n",
        "      elif level1 < level2:\n",
        "        data1.loc[x, 'level_change'] = 'lower'\n",
        "      else:\n",
        "        data1.loc[x, 'level_change'] = 'same'\n",
        "\n",
        "    except: #if the loop breaks - countries which are in data1 but not in data2 are printed out\n",
        "      print(x + ' - not included in both years') \n",
        "\n",
        "  return data1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4MUqygGxnwM"
      },
      "source": [
        "indicator_income_data_cleaned.iloc[1].pd.Index.name"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}